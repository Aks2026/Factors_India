{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import os\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pyodbc\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import xlsxwriter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSVs into DataFrames (replace with actual file paths)\n",
    "lowvol_long = pd.read_csv('LowVolLongNAV.csv').drop(columns=['Unnamed: 0'])\n",
    "lowvol_short = pd.read_csv('LowVolShortNAV.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "value_long = pd.read_csv('ValueLongNAV.csv').drop(columns=['Unnamed: 0'])\n",
    "value_short = pd.read_csv('ValueShortNAV.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "mom_long = pd.read_csv('MomLongNAV.csv').drop(columns=['Unnamed: 0'])\n",
    "mom_short = pd.read_csv('MomShortNAV.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Merge long and short for each category on 'Date'\n",
    "lowvol_df = pd.merge(lowvol_long, lowvol_short, on='Date', suffixes=('_long', '_short'))\n",
    "value_df = pd.merge(value_long, value_short, on='Date', suffixes=('_long', '_short'))\n",
    "mom_df = pd.merge(mom_long, mom_short, on='Date', suffixes=('_long', '_short'))\n",
    "# Function to calculate daily returns, long-short returns, and NAV\n",
    "def calculate_returns_and_nav(df, factor_name):\n",
    "\n",
    "    # Calculate Daily Returns for both long and short portfolios\n",
    "    df['long_return'] = df['Close_long'].pct_change()\n",
    "    df['short_return'] = df['Close_short'].pct_change()\n",
    "\n",
    "    # Calculate the Long-Short Return\n",
    "    df['long_short_return'] = df['long_return'] - df['short_return']\n",
    "\n",
    "    # Rebase the Long-Short Return to calculate NAV\n",
    "    df[f'{factor_name}_LS_NAV'] = (1 + df['long_short_return']).cumprod() * 100\n",
    "\n",
    "    # Keep only the 'Date', 'NAV_Long', and 'Factor_LS_NAV' columns\n",
    "    return df[['Date', f'{factor_name}_LS_NAV']]\n",
    "\n",
    "# Apply the function to each category\n",
    "lowvol_result = calculate_returns_and_nav(lowvol_df, 'LowVol')\n",
    "value_result = calculate_returns_and_nav(value_df, 'Value')\n",
    "mom_result = calculate_returns_and_nav(mom_df, 'Mom')\n",
    "\n",
    "# Load the CSVs for Quality and LowVol\n",
    "quality_long = pd.read_csv('QualityNAV.csv')\n",
    "lowvol_short = pd.read_csv('LowVolShortNAV.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Merge Quality Long with LowVol Short on 'Date'\n",
    "quality_df = pd.merge(quality_long, lowvol_short, on='Date', suffixes=('_long', '_short'))\n",
    "\n",
    "# Function to calculate Quality Long-Short NAV using LowVol's short returns\n",
    "def calculate_quality_long_short_nav(df):\n",
    "    # Calculate Daily Return for the Quality Long portfolio\n",
    "    df['long_return'] = df['Close_long'].pct_change()\n",
    "\n",
    "    # Use LowVol's short returns for the short leg\n",
    "    df['short_return'] = df['Close_short'].pct_change()\n",
    "\n",
    "    # Calculate Long-Short Return\n",
    "    df['long_short_return'] = df['long_return'] - df['short_return']\n",
    "\n",
    "    # Rebase the Long-Short Return to calculate NAV\n",
    "    df['Quality_LS_NAV'] = (1 + df['long_short_return']).cumprod() * 100\n",
    "\n",
    "    # Keep only the necessary columns: Date, NAV_Long, and the new Quality_LS_NAV\n",
    "    return df[['Date' ,'Quality_LS_NAV']]\n",
    "\n",
    "# Apply the function to the merged DataFrame\n",
    "quality_result = calculate_quality_long_short_nav(quality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              0\n",
      "LowVol_LS_NAV     2\n",
      "Value_LS_NAV      2\n",
      "Mom_LS_NAV        1\n",
      "Quality_LS_NAV    2\n",
      "dtype: int64\n",
      "            LowVol_LS_NAV  Value_LS_NAV  Mom_LS_NAV  Quality_LS_NAV\n",
      "Date                                                               \n",
      "2008-02-12     114.579716    101.379808  104.393410       99.634496\n",
      "2008-03-11      95.946576    107.545863   94.355441       89.194295\n",
      "2008-03-12     113.447356    100.771103  103.416353      100.660266\n",
      "2008-04-11      92.080594    107.188479   94.631684       90.241873\n",
      "2008-05-12     106.967390     97.737971  100.503140       99.467992\n",
      "            LowVol_LS_NAV  Value_LS_NAV  Mom_LS_NAV  Quality_LS_NAV\n",
      "Date                                                               \n",
      "2025-01-14      42.978996    163.532547  809.864308       31.592801\n",
      "2025-01-15      42.953132    162.882903  805.724957       31.682044\n",
      "2025-01-16      41.943974    165.281858  814.498894       31.351472\n",
      "2025-01-17      41.555501    163.963328  824.373420       30.820443\n",
      "2025-01-20      40.834860    167.360438  834.843404       30.905716\n"
     ]
    }
   ],
   "source": [
    "# Ensure all Date columns are in datetime format before merging\n",
    "lowvol_result['Date'] = pd.to_datetime(lowvol_result['Date'])\n",
    "value_result['Date'] = pd.to_datetime(value_result['Date'])\n",
    "mom_result['Date'] = pd.to_datetime(mom_result['Date'])\n",
    "quality_result['Date'] = pd.to_datetime(quality_result['Date'])\n",
    "\n",
    "# Merge all results\n",
    "merged_result = pd.merge(lowvol_result, value_result, on='Date', how='outer')\n",
    "merged_result = pd.merge(merged_result, mom_result, on='Date', how='outer')\n",
    "merged_result = pd.merge(merged_result, quality_result, on='Date', how='outer')\n",
    "\n",
    "# Sort and drop NaN values cautiously\n",
    "merged_result = merged_result.sort_values(by='Date')\n",
    "\n",
    "# Check for missing data before dropping\n",
    "print(merged_result.isna().sum())  # Identify missing data per column\n",
    "\n",
    "# Drop only if you are sure itâ€™s needed\n",
    "merged_result = merged_result.dropna()\n",
    "\n",
    "# Ensure Date is the index and in correct format\n",
    "merged_result.set_index('Date', inplace=True)\n",
    "merged_result.index = pd.to_datetime(merged_result.index)\n",
    "\n",
    "# Verify final output\n",
    "print(merged_result.head())\n",
    "print(merged_result.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def calculate_rolling_correlations(df, window_years):\n",
    "#     window = window_years * 252  # Assuming 252 trading days per year\n",
    "#     pairs = ['LowVol_LS_NAV-Value_LS_NAV', 'LowVol_LS_NAV-Mom_LS_NAV', 'LowVol_LS_NAV-Quality_LS_NAV',\n",
    "#              'Value_LS_NAV-Mom_LS_NAV', 'Value_LS_NAV-Quality_LS_NAV', 'Mom_LS_NAV-Quality_LS_NAV']\n",
    "    \n",
    "#     corr_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "#     for pair in pairs:\n",
    "#         factor1, factor2 = pair.split('-')\n",
    "#         corr_df[f'{pair}_{window_years}Y'] = df[factor1].rolling(window).corr(df[factor2])\n",
    "    \n",
    "#     return corr_df\n",
    "\n",
    "# def plot_correlations(df, corr_df, window_years, save_path):\n",
    "#     # Increase figure size and DPI for better quality\n",
    "#     plt.figure(figsize=(20, 15), dpi=300)\n",
    "    \n",
    "#     pairs = ['LowVol_LS_NAV-Value_LS_NAV', 'LowVol_LS_NAV-Mom_LS_NAV', 'LowVol_LS_NAV-Quality_LS_NAV',\n",
    "#              'Value_LS_NAV-Mom_LS_NAV', 'Value_LS_NAV-Quality_LS_NAV', 'Mom_LS_NAV-Quality_LS_NAV']\n",
    "    \n",
    "#     for i, pair in enumerate(pairs, 1):\n",
    "#         plt.subplot(2, 3, i)\n",
    "        \n",
    "#         # Plot with improved styling\n",
    "#         plt.plot(corr_df[f'{pair}_{window_years}Y'], linewidth=1.5, color='#1f77b4')\n",
    "        \n",
    "#         # Improve title formatting\n",
    "#         plt.title(f'{window_years}Y Rolling Correlation:\\n{pair}', pad=20, fontsize=12)\n",
    "        \n",
    "#         # Improve axis formatting\n",
    "#         plt.grid(True, linestyle='--', alpha=0.7)\n",
    "#         plt.ylim(-1, 1)  # Set fixed y-axis limits for correlation\n",
    "        \n",
    "#         # Format x-axis\n",
    "#         plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "#         # Add y-axis label\n",
    "#         plt.ylabel('Correlation')\n",
    "        \n",
    "#         # Add horizontal lines at important correlation levels\n",
    "#         plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "#         plt.axhline(y=0.5, color='gray', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "#         plt.axhline(y=-0.5, color='gray', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "#     # Adjust layout to prevent cutoff\n",
    "#     plt.tight_layout(pad=3.0)\n",
    "    \n",
    "#     # Save with high quality\n",
    "#     plt.savefig(f'{save_path}_{window_years}Y_correlations.pdf', \n",
    "#                 bbox_inches='tight', \n",
    "#                 pad_inches=0.5)\n",
    "#     plt.close()\n",
    "\n",
    "# def calculate_full_period_correlations(df):\n",
    "#     corr_matrix = df.corr()\n",
    "#     corr_matrix.to_csv('full_period_correlations.csv')\n",
    "#     return corr_matrix\n",
    "\n",
    "# # Run the analysis\n",
    "# def run_correlation_analysis(merged_result):\n",
    "#     # Calculate rolling correlations for different windows\n",
    "#     corr_1y = calculate_rolling_correlations(merged_result, 1)\n",
    "#     corr_3y = calculate_rolling_correlations(merged_result, 3)\n",
    "#     corr_5y = calculate_rolling_correlations(merged_result, 5)\n",
    "\n",
    "#     # Create plots\n",
    "#     plot_correlations(merged_result, corr_1y, 1, 'rolling')\n",
    "#     plot_correlations(merged_result, corr_3y, 3, 'rolling')\n",
    "#     plot_correlations(merged_result, corr_5y, 5, 'rolling')\n",
    "\n",
    "#     # Calculate and save full-period correlations\n",
    "#     full_period_corr = calculate_full_period_correlations(merged_result)\n",
    "    \n",
    "#     return corr_1y, corr_3y, corr_5y, full_period_corr\n",
    "\n",
    "# # Execute\n",
    "# corr_1y, corr_3y, corr_5y, full_period_corr = run_correlation_analysis(merged_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete. Correlation plots have been saved to a single PDF file.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.dates import YearLocator, DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_individual_correlations(df, window_years=1, save_path='factor_correlations.pdf'):\n",
    "    # Ensure 'date' column exists and set it as index\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.set_index('date')\n",
    "    \n",
    "    # Drop any rows with NaN values to prevent incorrect date handling\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Calculate window size (252 trading days per year)\n",
    "    window = window_years * 252\n",
    "    \n",
    "    # Define all factor pairs\n",
    "    pairs = [\n",
    "        ('LowVol_LS_NAV', 'Value_LS_NAV'),\n",
    "        ('LowVol_LS_NAV', 'Mom_LS_NAV'),\n",
    "        ('LowVol_LS_NAV', 'Quality_LS_NAV'),\n",
    "        ('Value_LS_NAV', 'Mom_LS_NAV'),\n",
    "        ('Value_LS_NAV', 'Quality_LS_NAV'),\n",
    "        ('Mom_LS_NAV', 'Quality_LS_NAV')\n",
    "    ]\n",
    "    \n",
    "    # Create PDF\n",
    "    with PdfPages(save_path) as pdf:\n",
    "        for factor1, factor2 in pairs:\n",
    "            # Calculate rolling correlation\n",
    "            rolling_corr = df[factor1].rolling(window).corr(df[factor2])\n",
    "            rolling_corr = rolling_corr.dropna()\n",
    "            \n",
    "            expanding_corr = df[factor1].expanding().corr(df[factor2])\n",
    "            expanding_corr = expanding_corr.dropna()\n",
    "            \n",
    "            # Calculate statistics\n",
    "            mean_corr = rolling_corr.mean()\n",
    "            min_corr = rolling_corr.min()\n",
    "            max_corr = rolling_corr.max()\n",
    "            std_corr = rolling_corr.std()\n",
    "            \n",
    "            # Calculate expanding percentiles\n",
    "            p10 = expanding_corr.expanding().quantile(0.10)\n",
    "            p75 = expanding_corr.expanding().quantile(0.75)\n",
    "            p95 = expanding_corr.expanding().quantile(0.95)\n",
    "            \n",
    "            # Create figure\n",
    "            fig, ax = plt.subplots(figsize=(12, 6), dpi=300)\n",
    "            \n",
    "            # Plot correlation\n",
    "            ax.plot(rolling_corr.index, rolling_corr.values, \n",
    "                   linewidth=1.5, \n",
    "                   color='#1f77b4', \n",
    "                   label=f'1Y Rolling Correlation')\n",
    "            \n",
    "            # Plot percentile bands\n",
    "            ax.plot(p10.index, p10.values, linestyle='dashed', color='gray', alpha=0.6, label='10th Percentile')\n",
    "            ax.plot(p75.index, p75.values, linestyle='dashed', color='green', alpha=0.6, label='75th Percentile')\n",
    "            ax.plot(p95.index, p95.values, linestyle='dashed', color='red', alpha=0.6, label='95th Percentile')\n",
    "            \n",
    "            # Add horizontal lines\n",
    "            ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "            ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "            ax.axhline(y=-0.5, color='gray', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "            \n",
    "            # Add mean correlation line\n",
    "            ax.axhline(y=mean_corr, color='red', linestyle='--', linewidth=1, alpha=0.5,\n",
    "                      label=f'Mean: {mean_corr:.2f}')\n",
    "            \n",
    "            # Add statistics box\n",
    "            stats_text = (f'Mean: {mean_corr:.2f}\\n'\n",
    "                         f'Min: {min_corr:.2f}\\n'\n",
    "                         f'Max: {max_corr:.2f}\\n'\n",
    "                         f'Std Dev: {std_corr:.2f}')\n",
    "            \n",
    "            # Place stats box in upper left corner\n",
    "            plt.text(0.02, 0.98, stats_text,\n",
    "                    transform=ax.transAxes,\n",
    "                    bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'),\n",
    "                    verticalalignment='top',\n",
    "                    fontsize=10)\n",
    "            \n",
    "            # Customize plot\n",
    "            plt.title(f'{factor1} vs {factor2}\\n1-Year Rolling Correlation', \n",
    "                     pad=20, \n",
    "                     fontsize=12)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.ylim(-1, 1)\n",
    "            \n",
    "            # Format axes\n",
    "            plt.ylabel('Correlation')\n",
    "            plt.xlabel('Date')\n",
    "            \n",
    "            # Format x-axis dates\n",
    "            ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "            fig.autofmt_xdate()  # Automatically format dates\n",
    "            \n",
    "            # Add legend\n",
    "            plt.legend(loc='upper right')\n",
    "            \n",
    "            # Adjust layout\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save to PDF\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        # Create and save summary statistics\n",
    "        summary_stats = pd.DataFrame(columns=['Pair', 'Mean Correlation', 'Min', 'Max', 'Std Dev'])\n",
    "        \n",
    "        for factor1, factor2 in pairs:\n",
    "            corr = df[factor1].rolling(window).corr(df[factor2])\n",
    "            new_row = pd.DataFrame({\n",
    "                'Pair': [f'{factor1} vs {factor2}'],\n",
    "                'Mean Correlation': [corr.mean()],\n",
    "                'Min': [corr.min()],\n",
    "                'Max': [corr.max()],\n",
    "                'Std Dev': [corr.std()]\n",
    "            })\n",
    "            summary_stats = pd.concat([summary_stats, new_row], ignore_index=True)\n",
    "        \n",
    "        summary_stats.to_csv('correlation_summary_stats.csv', index=False)\n",
    "        return summary_stats\n",
    "\n",
    "# Run the analysis\n",
    "summary_stats = plot_individual_correlations(merged_result)\n",
    "print(\"\\nAnalysis complete. Correlation plots have been saved to a single PDF file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex([], dtype='datetime64[ns]', name='Date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(merged_result.index[merged_result.index < '2000-01-01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
