{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import xlsxwriter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9767e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data = pd.read_csv('stockPriceData.csv')\n",
    "# etf_indices = pd.read_csv('etf_indices_18_2_2025.csv')\n",
    "# price_data = price_data[~(price_data['Symbol'].isin(etf_indices['Symbol']))]\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'])\n",
    "\n",
    "\n",
    "# Ensure the DataFrame is sorted by Symbol and Date\n",
    "price_data = price_data.sort_values(by=['Date'], ascending=True)\n",
    "\n",
    "# Calculate the 6-month rolling average of Mcap for each symbol\n",
    "\n",
    "top_1000 =  price_data.groupby('Date', group_keys= False).apply(lambda x: x.sort_values(by='Mcap', ascending=False).head(500))\n",
    "price_data_500 = price_data[price_data['Symbol'].isin(top_1000['Symbol'])]\n",
    "\n",
    "df = price_data_500[['Date','Symbol', 'Close', 'Mcap','Volume']]\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "df = df.sort_values(by=['Date','Mcap'], ascending=[True,False])\n",
    "df = df.sort_values(['Symbol', 'Date'])\n",
    "df['PrevClose'] = df.groupby('Symbol')['Close'].shift(1)\n",
    "df['returns'] = (df['Close'] - df['PrevClose']) / df['PrevClose']\n",
    "df = df[df.index >= '2006-01-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cbdf001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating beta for multiple time periods...\n",
      "Calculating 1M beta (window: 21 days)...\n",
      "Calculating 2M beta (window: 42 days)...\n",
      "Calculating 3M beta (window: 63 days)...\n",
      "Calculating 6M beta (window: 126 days)...\n",
      "Calculating 12M beta (window: 252 days)...\n",
      "\n",
      "Beta columns created: ['Beta_1M', 'Beta_2M', 'Beta_3M', 'Beta_6M', 'Beta_12M']\n",
      "\n",
      "Applying cross-sectional winsorization (5th and 95th percentiles)...\n",
      "Winsorizing Beta_1M...\n",
      "Winsorizing Beta_2M...\n",
      "Winsorizing Beta_3M...\n",
      "Winsorizing Beta_6M...\n",
      "Winsorizing Beta_12M...\n",
      "Winsorized beta columns created: ['Beta_1M_Winsorized', 'Beta_2M_Winsorized', 'Beta_3M_Winsorized', 'Beta_6M_Winsorized', 'Beta_12M_Winsorized']\n",
      "\n",
      "Comparison: Original vs Winsorized Beta Statistics:\n",
      "================================================================================\n",
      "\n",
      "Beta_1M:\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.9665       0.9671          +0.07%\n",
      "Std Dev              1.1917       0.7780         -34.72%\n",
      "Min                  -428.6005    -2.2484        +99.48%\n",
      "Max                  197.3329     4.7400         -97.60%\n",
      "Winsorized (Lower)   2,483,209                    49.74%\n",
      "Winsorized (Upper)   2,477,562                    49.63%\n",
      "Total Winsorized     4,960,771                    99.38%\n",
      "\n",
      "Beta_2M:\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.9854       0.9857          +0.03%\n",
      "Std Dev              0.8305       0.6144         -26.02%\n",
      "Min                  -174.7259    -0.9151        +99.48%\n",
      "Max                  106.3056     3.5895         -96.62%\n",
      "Winsorized (Lower)   2,449,306                    49.37%\n",
      "Winsorized (Upper)   2,449,593                    49.38%\n",
      "Total Winsorized     4,898,899                    98.75%\n",
      "\n",
      "Beta_3M:\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.9920       0.9921          +0.01%\n",
      "Std Dev              0.7232       0.5495         -24.02%\n",
      "Min                  -183.2127    -0.4340        +99.76%\n",
      "Max                  57.1476      3.1683         -94.46%\n",
      "Winsorized (Lower)   2,419,711                    49.09%\n",
      "Winsorized (Upper)   2,417,792                    49.05%\n",
      "Total Winsorized     4,837,503                    98.13%\n",
      "\n",
      "Beta_6M:\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.9921       0.9920          -0.01%\n",
      "Std Dev              0.5800       0.4689         -19.16%\n",
      "Min                  -71.8788     -0.1716        +99.76%\n",
      "Max                  19.0763      2.5262         -86.76%\n",
      "Winsorized (Lower)   2,334,872                    48.28%\n",
      "Winsorized (Upper)   2,322,018                    48.01%\n",
      "Total Winsorized     4,656,890                    96.29%\n",
      "\n",
      "Beta_12M:\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.9858       0.9858          -0.00%\n",
      "Std Dev              0.4986       0.4172         -16.34%\n",
      "Min                  -29.0440     0.0488        +100.17%\n",
      "Max                  8.1290       2.3460         -71.14%\n",
      "Winsorized (Lower)   2,161,732                    46.46%\n",
      "Winsorized (Upper)   2,148,603                    46.18%\n",
      "Total Winsorized     4,310,335                    92.64%\n",
      "\n",
      "Sample of calculated betas (showing both original and winsorized):\n",
      "================================================================================\n",
      "      Date    Symbol  Beta_1M  Beta_2M  Beta_3M  Beta_6M  Beta_12M  Beta_1M_Winsorized  Beta_2M_Winsorized  Beta_3M_Winsorized  Beta_6M_Winsorized  Beta_12M_Winsorized\n",
      "2025-06-02 ZYDUSWELL 0.542386 0.360259 0.520963 0.604233  0.608544            0.176384            0.395905            0.871543            1.059020             0.969552\n",
      "2025-06-03 ZYDUSWELL 0.526440 0.354409 0.508669 0.599803  0.608561            1.166144            1.408539            1.453311            1.678117             1.457639\n",
      "2025-06-04 ZYDUSWELL 0.532374 0.290453 0.490840 0.591668  0.604930            1.129668            1.590000            1.597076            1.832607             1.704080\n",
      "2025-06-05 ZYDUSWELL 0.441507 0.251416 0.491290 0.613770  0.603329            0.156725            0.615681            0.583608            0.822846             0.746267\n",
      "2025-06-06 ZYDUSWELL 0.517991 0.281069 0.526344 0.642000  0.616776            0.517991            0.281069            0.526344            0.642000             0.616776\n",
      "\n",
      "Example - Latest beta values for first stock in dataset:\n",
      "Stock: 360ONE\n",
      "Period   Original     Winsorized   Difference  \n",
      "--------------------------------------------------\n",
      "1M       N/A          N/A          N/A         \n",
      "2M       N/A          N/A          N/A         \n",
      "3M       N/A          N/A          N/A         \n",
      "6M       N/A          N/A          N/A         \n",
      "12M      N/A          N/A          N/A         \n",
      "\n",
      "Winsorization Analysis for 2025-06-06 - 12M Beta:\n",
      "------------------------------------------------------------\n",
      "Total securities: 1187\n",
      "5th percentile threshold: 0.4929\n",
      "95th percentile threshold: 1.7393\n",
      "Values winsorized at lower bound: 60 (5.1%)\n",
      "Values winsorized at upper bound: 60 (5.1%)\n",
      "Total values winsorized: 120 (10.1%)\n",
      "\n",
      "Beta calculation and winsorization completed!\n",
      "Final dataset shape: (5023278, 31)\n",
      "Total beta columns (original + winsorized): 10\n"
     ]
    }
   ],
   "source": [
    "# Your existing code for data preparation\n",
    "nifty500_df = pd.read_csv('nifty_500_index_data.csv')\n",
    "nifty500_df = nifty500_df.drop(nifty500_df.columns[0], axis=1)\n",
    "nifty500_df = nifty500_df.rename(columns={\n",
    "    'index_date': 'Date',\n",
    "    'index_value': 'Nifty 500 '\n",
    "})\n",
    "nifty500_df['Date'] = pd.to_datetime(nifty500_df['Date'])\n",
    "nifty500_df = nifty500_df[['Date','Nifty 500 ']]\n",
    "nifty500_df['Date'] = pd.to_datetime(nifty500_df['Date'], format='%d-%m-%Y')\n",
    "nifty500_df['Date'] = nifty500_df['Date'].dt.strftime('%Y-%m-%d')\n",
    "nifty500_df['Date'] = pd.to_datetime(nifty500_df['Date'])\n",
    "nifty500_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Calculate daily returns for securities\n",
    "df['Security_Daily_Return'] = df.groupby('Symbol')['Close'].pct_change()\n",
    "\n",
    "# Calculate market daily returns\n",
    "nifty500_df['Market_Daily_Return'] = nifty500_df['Nifty 500 '].pct_change()\n",
    "nifty500_df = nifty500_df.reset_index()\n",
    "\n",
    "# Merge the security dataframe with the market dataframe on Date\n",
    "df = pd.merge(df, nifty500_df, on='Date')\n",
    "\n",
    "# Define rolling windows for different time periods (in trading days)\n",
    "rolling_windows = {\n",
    "    '1M': 21,    # 1 month ≈ 21 trading days\n",
    "    '2M': 42,    # 2 months ≈ 42 trading days\n",
    "    '3M': 63,    # 3 months ≈ 63 trading days\n",
    "    '6M': 126,   # 6 months ≈ 126 trading days\n",
    "    '12M': 252   # 12 months ≈ 252 trading days\n",
    "}\n",
    "\n",
    "# Enhanced rolling beta calculation function\n",
    "def calculate_rolling_beta(group, window):\n",
    "    \"\"\"\n",
    "    Calculate rolling beta for a given window\n",
    "    Beta = Covariance(Security Returns, Market Returns) / Variance(Market Returns)\n",
    "    \"\"\"\n",
    "    # Calculate rolling covariance between security and market returns\n",
    "    rolling_cov = group['Security_Daily_Return'].rolling(window=window).cov(\n",
    "        group['Market_Daily_Return']\n",
    "    )\n",
    "    \n",
    "    # Calculate rolling variance of market returns\n",
    "    rolling_var = group['Market_Daily_Return'].rolling(window=window).var()\n",
    "    \n",
    "    # Calculate beta (handle division by zero)\n",
    "    beta = rolling_cov / rolling_var\n",
    "    \n",
    "    return beta\n",
    "\n",
    "# Calculate beta for all time periods\n",
    "print(\"Calculating beta for multiple time periods...\")\n",
    "\n",
    "for period, window in rolling_windows.items():\n",
    "    print(f\"Calculating {period} beta (window: {window} days)...\")\n",
    "    \n",
    "    # Calculate rolling beta for each security\n",
    "    df[f'Beta_{period}'] = (\n",
    "        df.groupby('Symbol', group_keys=False)\n",
    "        .apply(lambda group: calculate_rolling_beta(group, window))\n",
    "    )\n",
    "    \n",
    "    # Calculate rolling average returns for reference\n",
    "    df[f'Avg_{period}_Security_Returns'] = (\n",
    "        df.groupby('Symbol')['Security_Daily_Return']\n",
    "        .apply(lambda x: x.rolling(window=window).mean())\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "# Calculate market rolling average returns for all periods\n",
    "for period, window in rolling_windows.items():\n",
    "    nifty500_df[f'Avg_{period}_Market_Returns'] = (\n",
    "        nifty500_df['Market_Daily_Return'].rolling(window=window).mean()\n",
    "    )\n",
    "\n",
    "# Merge updated market data back to main dataframe\n",
    "df = df.drop(columns=['Market_Daily_Return'], errors='ignore')  # Remove old column to avoid duplicates\n",
    "df = pd.merge(df, nifty500_df, on='Date', how='left')\n",
    "\n",
    "# Display beta columns\n",
    "beta_columns = [col for col in df.columns if col.startswith('Beta_')]\n",
    "print(f\"\\nBeta columns created: {beta_columns}\")\n",
    "\n",
    "# WINSORIZATION: Cap bottom and top 5% values cross-sectionally each day\n",
    "print(\"\\nApplying cross-sectional winsorization (5th and 95th percentiles)...\")\n",
    "\n",
    "def winsorize_cross_sectional(group, column, lower_pct=0.05, upper_pct=0.95):\n",
    "    \"\"\"\n",
    "    Winsorize values cross-sectionally for a given date\n",
    "    \n",
    "    Parameters:\n",
    "    group: DataFrame group for a specific date\n",
    "    column: Column name to winsorize\n",
    "    lower_pct: Lower percentile threshold (default 0.05 for 5%)\n",
    "    upper_pct: Upper percentile threshold (default 0.95 for 95%)\n",
    "    \"\"\"\n",
    "    # Get non-null values for the column\n",
    "    valid_values = group[column].dropna()\n",
    "    \n",
    "    if len(valid_values) == 0:\n",
    "        return group[column]  # Return original if no valid values\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    lower_threshold = valid_values.quantile(lower_pct)\n",
    "    upper_threshold = valid_values.quantile(upper_pct)\n",
    "    \n",
    "    # Apply winsorization\n",
    "    winsorized = group[column].copy()\n",
    "    winsorized = winsorized.clip(lower=lower_threshold, upper=upper_threshold)\n",
    "    \n",
    "    return winsorized\n",
    "\n",
    "# Apply winsorization to each beta column\n",
    "for beta_col in beta_columns:\n",
    "    print(f\"Winsorizing {beta_col}...\")\n",
    "    \n",
    "    # Create winsorized version\n",
    "    winsorized_col = f'{beta_col}_Winsorized'\n",
    "    \n",
    "    # Group by date and apply winsorization\n",
    "    df[winsorized_col] = (\n",
    "        df.groupby('Date', group_keys=False)\n",
    "        .apply(lambda group: winsorize_cross_sectional(group, beta_col))\n",
    "        .values\n",
    "    )\n",
    "\n",
    "# Update beta columns list to include winsorized versions\n",
    "winsorized_beta_columns = [col for col in df.columns if col.startswith('Beta_') and col.endswith('_Winsorized')]\n",
    "all_beta_columns = beta_columns + winsorized_beta_columns\n",
    "\n",
    "print(f\"Winsorized beta columns created: {winsorized_beta_columns}\")\n",
    "\n",
    "# Compare original vs winsorized statistics\n",
    "print(\"\\nComparison: Original vs Winsorized Beta Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, original_col in enumerate(beta_columns):\n",
    "    winsorized_col = f'{original_col}_Winsorized'\n",
    "    \n",
    "    original_data = df[original_col].dropna()\n",
    "    winsorized_data = df[winsorized_col].dropna()\n",
    "    \n",
    "    if len(original_data) > 0 and len(winsorized_data) > 0:\n",
    "        print(f\"\\n{original_col}:\")\n",
    "        print(f\"{'Metric':<20} {'Original':<12} {'Winsorized':<12} {'Change':<10}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        orig_mean = original_data.mean()\n",
    "        wins_mean = winsorized_data.mean()\n",
    "        orig_std = original_data.std()\n",
    "        wins_std = winsorized_data.std()\n",
    "        orig_min = original_data.min()\n",
    "        wins_min = winsorized_data.min()\n",
    "        orig_max = original_data.max()\n",
    "        wins_max = winsorized_data.max()\n",
    "        \n",
    "        # Display comparison\n",
    "        print(f\"{'Mean':<20} {orig_mean:<12.4f} {wins_mean:<12.4f} {((wins_mean-orig_mean)/orig_mean*100):>+8.2f}%\")\n",
    "        print(f\"{'Std Dev':<20} {orig_std:<12.4f} {wins_std:<12.4f} {((wins_std-orig_std)/orig_std*100):>+8.2f}%\")\n",
    "        print(f\"{'Min':<20} {orig_min:<12.4f} {wins_min:<12.4f} {((wins_min-orig_min)/abs(orig_min)*100):>+8.2f}%\")\n",
    "        print(f\"{'Max':<20} {orig_max:<12.4f} {wins_max:<12.4f} {((wins_max-orig_max)/abs(orig_max)*100):>+8.2f}%\")\n",
    "        \n",
    "        # Count of winsorized values\n",
    "        lower_wins = (df[original_col] < df[winsorized_col]).sum()\n",
    "        upper_wins = (df[original_col] > df[winsorized_col]).sum()\n",
    "        total_wins = lower_wins + upper_wins\n",
    "        total_obs = len(winsorized_data)\n",
    "        \n",
    "        print(f\"{'Winsorized (Lower)':<20} {lower_wins:<12,} {'':<12} {(lower_wins/total_obs*100):>8.2f}%\")\n",
    "        print(f\"{'Winsorized (Upper)':<20} {upper_wins:<12,} {'':<12} {(upper_wins/total_obs*100):>8.2f}%\")\n",
    "        print(f\"{'Total Winsorized':<20} {total_wins:<12,} {'':<12} {(total_wins/total_obs*100):>8.2f}%\")\n",
    "\n",
    "# Optional: Create a sample view of the results\n",
    "print(\"\\nSample of calculated betas (showing both original and winsorized):\")\n",
    "print(\"=\" * 80)\n",
    "sample_cols = ['Date', 'Symbol'] + all_beta_columns\n",
    "if len(df) > 0:\n",
    "    # Show last 5 rows with all beta calculations\n",
    "    sample_df = df[sample_cols].tail(5)\n",
    "    print(sample_df.to_string(index=False))\n",
    "\n",
    "# Enhanced function to get beta for a specific stock and time period\n",
    "def get_stock_beta(symbol, period='12M', latest=True, winsorized=True):\n",
    "    \"\"\"\n",
    "    Get beta for a specific stock and time period\n",
    "    \n",
    "    Parameters:\n",
    "    symbol: Stock symbol\n",
    "    period: Time period ('1M', '2M', '3M', '6M', '12M')\n",
    "    latest: If True, returns latest beta; if False, returns all betas\n",
    "    winsorized: If True, returns winsorized beta; if False, returns original beta\n",
    "    \"\"\"\n",
    "    stock_data = df[df['Symbol'] == symbol]\n",
    "    \n",
    "    if winsorized:\n",
    "        beta_col = f'Beta_{period}_Winsorized'\n",
    "    else:\n",
    "        beta_col = f'Beta_{period}'\n",
    "    \n",
    "    if beta_col not in df.columns:\n",
    "        print(f\"Beta for period {period} ({'winsorized' if winsorized else 'original'}) not calculated\")\n",
    "        return None\n",
    "    \n",
    "    if latest:\n",
    "        # Return the most recent non-null beta\n",
    "        latest_beta = stock_data[beta_col].dropna().iloc[-1] if len(stock_data[beta_col].dropna()) > 0 else None\n",
    "        return latest_beta\n",
    "    else:\n",
    "        # Return all beta values for the stock\n",
    "        return stock_data[['Date', beta_col]].dropna()\n",
    "\n",
    "# Function to analyze winsorization impact for a specific date\n",
    "def analyze_winsorization_by_date(target_date, beta_period='12M'):\n",
    "    \"\"\"\n",
    "    Analyze the impact of winsorization for a specific date\n",
    "    \n",
    "    Parameters:\n",
    "    target_date: Date to analyze (string in 'YYYY-MM-DD' format)\n",
    "    beta_period: Beta period to analyze\n",
    "    \"\"\"\n",
    "    target_date = pd.to_datetime(target_date)\n",
    "    date_data = df[df['Date'] == target_date]\n",
    "    \n",
    "    if len(date_data) == 0:\n",
    "        print(f\"No data found for date {target_date}\")\n",
    "        return\n",
    "    \n",
    "    original_col = f'Beta_{beta_period}'\n",
    "    winsorized_col = f'Beta_{beta_period}_Winsorized'\n",
    "    \n",
    "    if original_col not in df.columns or winsorized_col not in df.columns:\n",
    "        print(f\"Beta columns for period {beta_period} not found\")\n",
    "        return\n",
    "    \n",
    "    original_values = date_data[original_col].dropna()\n",
    "    winsorized_values = date_data[winsorized_col].dropna()\n",
    "    \n",
    "    if len(original_values) == 0:\n",
    "        print(f\"No valid beta values for date {target_date}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    p5 = original_values.quantile(0.05)\n",
    "    p95 = original_values.quantile(0.95)\n",
    "    \n",
    "    # Count winsorized values\n",
    "    lower_winsorized = (original_values < p5).sum()\n",
    "    upper_winsorized = (original_values > p95).sum()\n",
    "    \n",
    "    print(f\"\\nWinsorization Analysis for {target_date.strftime('%Y-%m-%d')} - {beta_period} Beta:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Total securities: {len(original_values)}\")\n",
    "    print(f\"5th percentile threshold: {p5:.4f}\")\n",
    "    print(f\"95th percentile threshold: {p95:.4f}\")\n",
    "    print(f\"Values winsorized at lower bound: {lower_winsorized} ({lower_winsorized/len(original_values)*100:.1f}%)\")\n",
    "    print(f\"Values winsorized at upper bound: {upper_winsorized} ({upper_winsorized/len(original_values)*100:.1f}%)\")\n",
    "    print(f\"Total values winsorized: {lower_winsorized + upper_winsorized} ({(lower_winsorized + upper_winsorized)/len(original_values)*100:.1f}%)\")\n",
    "\n",
    "# Example usage of the enhanced functions\n",
    "print(f\"\\nExample - Latest beta values for first stock in dataset:\")\n",
    "if len(df) > 0:\n",
    "    first_symbol = df['Symbol'].iloc[0]\n",
    "    print(f\"Stock: {first_symbol}\")\n",
    "    print(f\"{'Period':<8} {'Original':<12} {'Winsorized':<12} {'Difference':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for period in rolling_windows.keys():\n",
    "        orig_beta = get_stock_beta(first_symbol, period, winsorized=False)\n",
    "        wins_beta = get_stock_beta(first_symbol, period, winsorized=True)\n",
    "        \n",
    "        if orig_beta is not None and wins_beta is not None:\n",
    "            diff = wins_beta - orig_beta\n",
    "            print(f\"{period:<8} {orig_beta:<12.4f} {wins_beta:<12.4f} {diff:<+12.4f}\")\n",
    "        else:\n",
    "            print(f\"{period:<8} {'N/A':<12} {'N/A':<12} {'N/A':<12}\")\n",
    "\n",
    "# Example: Analyze winsorization for the latest date\n",
    "if len(df) > 0:\n",
    "    latest_date = df['Date'].max()\n",
    "    analyze_winsorization_by_date(latest_date.strftime('%Y-%m-%d'), '12M')\n",
    "\n",
    "print(\"\\nBeta calculation and winsorization completed!\")\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"Total beta columns (original + winsorized): {len(all_beta_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d40d9f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating momentum ratios...\n",
      "\n",
      "Applying cross-sectional winsorization to momentum ratios (5th and 95th percentiles)...\n",
      "Winsorizing MR1...\n",
      "Winsorizing MR2...\n",
      "Winsorizing MR3...\n",
      "Winsorizing MR6...\n",
      "Winsorizing MR12...\n",
      "\n",
      "Comparison: Original vs Winsorized Momentum Statistics:\n",
      "================================================================================\n",
      "\n",
      "MR1 (Period: 21 days):\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.0198       0.0141         -28.87%\n",
      "Std Dev              0.2708       0.1400         -48.31%\n",
      "Min                  -0.9868      -0.6349        +35.67%\n",
      "Max                  136.0588     1.0853         -99.20%\n",
      "Winsorized (Lower)   2,127,912                    49.70%\n",
      "Winsorized (Upper)   2,124,054                    49.61%\n",
      "Total Winsorized     4,251,966                    99.32%\n",
      "\n",
      "MR2 (Period: 42 days):\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.0421       0.0303         -28.13%\n",
      "Std Dev              0.5908       0.2067         -65.01%\n",
      "Min                  -0.9865      -0.6993        +29.11%\n",
      "Max                  252.9778     1.9781         -99.22%\n",
      "Winsorized (Lower)   2,099,291                    49.37%\n",
      "Winsorized (Upper)   2,095,072                    49.27%\n",
      "Total Winsorized     4,194,363                    98.65%\n",
      "\n",
      "MR3 (Period: 63 days):\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.0665       0.0468         -29.52%\n",
      "Std Dev              0.9281       0.2612         -71.86%\n",
      "Min                  -0.9866      -0.7470        +24.28%\n",
      "Max                  282.8667     2.1001         -99.26%\n",
      "Winsorized (Lower)   2,068,419                    48.98%\n",
      "Winsorized (Upper)   2,068,779                    48.99%\n",
      "Total Winsorized     4,137,198                    97.97%\n",
      "\n",
      "MR6 (Period: 126 days):\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.1690       0.1070         -36.65%\n",
      "Std Dev              3.4041       0.4140         -87.84%\n",
      "Min                  -0.9866      -0.8211        +16.77%\n",
      "Max                  986.3704     3.1524         -99.68%\n",
      "Winsorized (Lower)   1,983,282                    47.96%\n",
      "Winsorized (Upper)   1,985,368                    48.01%\n",
      "Total Winsorized     3,968,650                    95.96%\n",
      "\n",
      "MR12 (Period: 252 days):\n",
      "Metric               Original     Winsorized   Change    \n",
      "------------------------------------------------------------\n",
      "Mean                 0.4321       0.2454         -43.21%\n",
      "Std Dev              9.6364       0.7083         -92.65%\n",
      "Min                  -0.9880      -0.8968         +9.23%\n",
      "Max                  2089.8333    4.8904         -99.77%\n",
      "Winsorized (Lower)   1,823,264                    45.99%\n",
      "Winsorized (Upper)   1,824,073                    46.01%\n",
      "Total Winsorized     3,647,337                    92.01%\n",
      "\n",
      "Replacing original momentum ratios with winsorized versions...\n",
      "  MR1 now contains winsorized values\n",
      "  MR2 now contains winsorized values\n",
      "  MR3 now contains winsorized values\n",
      "  MR6 now contains winsorized values\n",
      "  MR12 now contains winsorized values\n",
      "Momentum winsorization completed!\n",
      "Available beta columns: ['Beta_1M', 'Beta_2M', 'Beta_3M', 'Beta_6M', 'Beta_12M', 'Beta_1M_Winsorized', 'Beta_2M_Winsorized', 'Beta_3M_Winsorized', 'Beta_6M_Winsorized', 'Beta_12M_Winsorized']\n",
      "MR1 -> Beta_1M_Winsorized ✓\n",
      "MR2 -> Beta_2M_Winsorized ✓\n",
      "MR3 -> Beta_3M_Winsorized ✓\n",
      "MR6 -> Beta_6M_Winsorized ✓\n",
      "MR12 -> Beta_12M_Winsorized ✓\n",
      "\n",
      "Final momentum-beta mapping:\n",
      "  MR1 normalized by Beta_1M_Winsorized\n",
      "  MR2 normalized by Beta_2M_Winsorized\n",
      "  MR3 normalized by Beta_3M_Winsorized\n",
      "  MR6 normalized by Beta_6M_Winsorized\n",
      "  MR12 normalized by Beta_12M_Winsorized\n",
      "\n",
      "Normalizing momentum ratios by corresponding beta periods...\n",
      "  MR1 normalized by Beta_1M_Winsorized\n",
      "  MR2 normalized by Beta_2M_Winsorized\n",
      "  MR3 normalized by Beta_3M_Winsorized\n",
      "  MR6 normalized by Beta_6M_Winsorized\n",
      "  MR12 normalized by Beta_12M_Winsorized\n",
      "Calculating cross-sectional statistics...\n",
      "Calculating Z-scores...\n",
      "Filtering to top 500 stocks by market cap...\n",
      "Calculating combined momentum scores...\n",
      "Momentum calculation completed with period-specific beta normalization!\n",
      "Note: All momentum ratios were winsorized cross-sectionally (5th-95th percentiles) before beta normalization\n",
      "\n",
      "Summary Statistics:\n",
      "Dataset shape: (2267971, 54)\n",
      "Date range: 2007-01-09 00:00:00 to 2025-06-06 00:00:00\n",
      "Number of unique symbols: 1244\n",
      "Processing steps: Momentum calculation → Cross-sectional winsorization → Beta normalization → Z-scores\n",
      "\n",
      "Momentum-related columns created: 22\n",
      "\n",
      "Sample data (last 5 rows):\n",
      "      Date     Symbol         Mcap       MR1      MR2       MR3       MR6      MR12     Z_MR1     Z_MR2     Z_MR3     Z_MR6    Z_MR12\n",
      "2025-06-06 BECTORFOOD 86055.603590  0.082453 0.019876 -0.116997 -0.269930 -0.316866  0.092036 -0.048245 -0.240745 -0.320997 -0.558199\n",
      "2025-06-06 GANESHHOUC 85705.251102  0.131593 0.127233  0.410019  0.196422  0.626099  0.153480 -0.007214  0.527111  0.017739  0.299106\n",
      "2025-06-06 METROPOLIS 85587.066136 -0.193129 0.117325  0.142163  0.083542  0.343571 -0.252556 -0.011000  0.136848 -0.064251  0.042243\n",
      "2025-06-06       CERA 85246.297239  0.110002 0.148634  0.505863  1.609350 -0.027415  0.126483  0.000966  0.666756  1.044020 -0.295042\n",
      "2025-06-06       KRBL 85215.706792 -1.108930 0.588994  0.343056  0.482630 -0.178099 -1.397683  0.169268  0.429548  0.225627 -0.432038\n",
      "\n",
      "Final Momentum Ratio Statistics (Winsorized + Beta-Normalized):\n",
      "======================================================================\n",
      "\n",
      "MR1 (winsorized, then normalized by Beta_1M_Winsorized):\n",
      "  Count: 2,244,037\n",
      "  Mean: 0.0055\n",
      "  Std: 1.0123\n",
      "  Min: -96.8428\n",
      "  Max: 71.1521\n",
      "  25th percentile: -0.0847\n",
      "  75th percentile: 0.0884\n",
      "\n",
      "MR2 (winsorized, then normalized by Beta_2M_Winsorized):\n",
      "  Count: 2,231,879\n",
      "  Mean: 0.0400\n",
      "  Std: 1.2188\n",
      "  Min: -95.9100\n",
      "  Max: 75.8088\n",
      "  25th percentile: -0.1090\n",
      "  75th percentile: 0.1452\n",
      "\n",
      "MR3 (winsorized, then normalized by Beta_3M_Winsorized):\n",
      "  Count: 2,221,218\n",
      "  Mean: 0.0613\n",
      "  Std: 1.2604\n",
      "  Min: -110.1496\n",
      "  Max: 141.0041\n",
      "  25th percentile: -0.1291\n",
      "  75th percentile: 0.1863\n",
      "\n",
      "MR6 (winsorized, then normalized by Beta_6M_Winsorized):\n",
      "  Count: 2,177,626\n",
      "  Mean: 0.1510\n",
      "  Std: 1.2815\n",
      "  Min: -98.3823\n",
      "  Max: 141.4061\n",
      "  25th percentile: -0.1746\n",
      "  75th percentile: 0.3183\n",
      "\n",
      "MR12 (winsorized, then normalized by Beta_12M_Winsorized):\n",
      "  Count: 2,091,943\n",
      "  Mean: 0.2782\n",
      "  Std: 1.0736\n",
      "  Min: -8.5288\n",
      "  Max: 31.3183\n",
      "  25th percentile: -0.2367\n",
      "  75th percentile: 0.5317\n",
      "\n",
      "Final Processing Summary:\n",
      "==================================================\n",
      "MR1 (21 days): Winsorized → Beta_1M_Winsorized normalized | Valid: 2,244,037/2,267,971 (98.9%)\n",
      "MR2 (42 days): Winsorized → Beta_2M_Winsorized normalized | Valid: 2,231,879/2,267,971 (98.4%)\n",
      "MR3 (63 days): Winsorized → Beta_3M_Winsorized normalized | Valid: 2,221,218/2,267,971 (97.9%)\n",
      "MR6 (126 days): Winsorized → Beta_6M_Winsorized normalized | Valid: 2,177,626/2,267,971 (96.0%)\n",
      "MR12 (252 days): Winsorized → Beta_12M_Winsorized normalized | Valid: 2,091,943/2,267,971 (92.2%)\n",
      "\n",
      "Final Normalized Momentum Score columns:\n",
      "  NormalizedMomentumScore_MR1_MR2_MR3_MR6_MR12\n",
      "    Range: [0.0764, 14.5582]\n",
      "    Mean: 1.0447\n",
      "\n",
      "Data is ready for further analysis!\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate log returns\n",
    "def calculate_log_returns(df):\n",
    "    df['LogReturn'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    return df.dropna()\n",
    "\n",
    "# Function to calculate momentum ratios\n",
    "def calculate_momentum_ratios(series, period):\n",
    "    return series / series.shift(period) - 1\n",
    "\n",
    "# Define periods for momentum ratios (in trading days)\n",
    "periods = {\n",
    "    'MR1': 21,   # 1 month\n",
    "    'MR2': 42,   # 2 months\n",
    "    'MR3': 63,   # 3 months\n",
    "    'MR6': 126,  # 6 months\n",
    "    'MR12': 252, # 12 months\n",
    "}\n",
    "\n",
    "# Apply log return calculation\n",
    "df = df.groupby('Symbol', group_keys=False).apply(calculate_log_returns)\n",
    "\n",
    "# Calculate momentum ratios for each period\n",
    "print(\"Calculating momentum ratios...\")\n",
    "for label, period in periods.items():\n",
    "    df[label] = df.groupby('Symbol')['Close'].transform(lambda x: calculate_momentum_ratios(x, period))\n",
    "\n",
    "# WINSORIZATION: Cap bottom and top 5% values cross-sectionally each day for momentum ratios\n",
    "print(\"\\nApplying cross-sectional winsorization to momentum ratios (5th and 95th percentiles)...\")\n",
    "\n",
    "def winsorize_momentum_cross_sectional(group, column, lower_pct=0.05, upper_pct=0.95):\n",
    "    \"\"\"\n",
    "    Winsorize momentum values cross-sectionally for a given date\n",
    "    \n",
    "    Parameters:\n",
    "    group: DataFrame group for a specific date\n",
    "    column: Column name to winsorize\n",
    "    lower_pct: Lower percentile threshold (default 0.05 for 5%)\n",
    "    upper_pct: Upper percentile threshold (default 0.95 for 95%)\n",
    "    \"\"\"\n",
    "    # Get non-null values for the column\n",
    "    valid_values = group[column].dropna()\n",
    "    \n",
    "    if len(valid_values) == 0:\n",
    "        return group[column]  # Return original if no valid values\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    lower_threshold = valid_values.quantile(lower_pct)\n",
    "    upper_threshold = valid_values.quantile(upper_pct)\n",
    "    \n",
    "    # Apply winsorization\n",
    "    winsorized = group[column].copy()\n",
    "    winsorized = winsorized.clip(lower=lower_threshold, upper=upper_threshold)\n",
    "    \n",
    "    return winsorized\n",
    "\n",
    "# Apply winsorization to each momentum ratio\n",
    "momentum_columns = list(periods.keys())\n",
    "for momentum_label in momentum_columns:\n",
    "    print(f\"Winsorizing {momentum_label}...\")\n",
    "    \n",
    "    # Create winsorized version\n",
    "    winsorized_col = f'{momentum_label}_Winsorized'\n",
    "    \n",
    "    # Group by date and apply winsorization\n",
    "    df[winsorized_col] = (\n",
    "        df.groupby('Date', group_keys=False)\n",
    "        .apply(lambda group: winsorize_momentum_cross_sectional(group, momentum_label))\n",
    "        .values\n",
    "    )\n",
    "\n",
    "# Update momentum columns to use winsorized versions\n",
    "winsorized_momentum_columns = [f'{label}_Winsorized' for label in periods.keys()]\n",
    "\n",
    "# Compare original vs winsorized momentum statistics\n",
    "print(\"\\nComparison: Original vs Winsorized Momentum Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, original_col in enumerate(momentum_columns):\n",
    "    winsorized_col = f'{original_col}_Winsorized'\n",
    "    \n",
    "    if original_col in df.columns and winsorized_col in df.columns:\n",
    "        original_data = df[original_col].dropna()\n",
    "        winsorized_data = df[winsorized_col].dropna()\n",
    "        \n",
    "        if len(original_data) > 0 and len(winsorized_data) > 0:\n",
    "            print(f\"\\n{original_col} (Period: {periods[original_col]} days):\")\n",
    "            print(f\"{'Metric':<20} {'Original':<12} {'Winsorized':<12} {'Change':<10}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            orig_mean = original_data.mean()\n",
    "            wins_mean = winsorized_data.mean()\n",
    "            orig_std = original_data.std()\n",
    "            wins_std = winsorized_data.std()\n",
    "            orig_min = original_data.min()\n",
    "            wins_min = winsorized_data.min()\n",
    "            orig_max = original_data.max()\n",
    "            wins_max = winsorized_data.max()\n",
    "            \n",
    "            # Display comparison\n",
    "            print(f\"{'Mean':<20} {orig_mean:<12.4f} {wins_mean:<12.4f} {((wins_mean-orig_mean)/abs(orig_mean)*100 if orig_mean != 0 else 0):>+8.2f}%\")\n",
    "            print(f\"{'Std Dev':<20} {orig_std:<12.4f} {wins_std:<12.4f} {((wins_std-orig_std)/abs(orig_std)*100 if orig_std != 0 else 0):>+8.2f}%\")\n",
    "            print(f\"{'Min':<20} {orig_min:<12.4f} {wins_min:<12.4f} {((wins_min-orig_min)/abs(orig_min)*100 if orig_min != 0 else 0):>+8.2f}%\")\n",
    "            print(f\"{'Max':<20} {orig_max:<12.4f} {wins_max:<12.4f} {((wins_max-orig_max)/abs(orig_max)*100 if orig_max != 0 else 0):>+8.2f}%\")\n",
    "            \n",
    "            # Count of winsorized values\n",
    "            lower_wins = (df[original_col] < df[winsorized_col]).sum()\n",
    "            upper_wins = (df[original_col] > df[winsorized_col]).sum()\n",
    "            total_wins = lower_wins + upper_wins\n",
    "            total_obs = len(winsorized_data)\n",
    "            \n",
    "            print(f\"{'Winsorized (Lower)':<20} {lower_wins:<12,} {'':<12} {(lower_wins/total_obs*100):>8.2f}%\")\n",
    "            print(f\"{'Winsorized (Upper)':<20} {upper_wins:<12,} {'':<12} {(upper_wins/total_obs*100):>8.2f}%\")\n",
    "            print(f\"{'Total Winsorized':<20} {total_wins:<12,} {'':<12} {(total_wins/total_obs*100):>8.2f}%\")\n",
    "\n",
    "# Replace original momentum columns with winsorized versions for further processing\n",
    "print(f\"\\nReplacing original momentum ratios with winsorized versions...\")\n",
    "for i, momentum_label in enumerate(momentum_columns):\n",
    "    winsorized_col = f'{momentum_label}_Winsorized'\n",
    "    if winsorized_col in df.columns:\n",
    "        # Drop original and rename winsorized to original name\n",
    "        df.drop(columns=[momentum_label], inplace=True)\n",
    "        df.rename(columns={winsorized_col: momentum_label}, inplace=True)\n",
    "        print(f\"  {momentum_label} now contains winsorized values\")\n",
    "\n",
    "print(\"Momentum winsorization completed!\")\n",
    "\n",
    "# Define mapping between momentum periods and corresponding beta columns\n",
    "momentum_beta_mapping = {\n",
    "    'MR1': 'Beta_1M_Winsorized',   # 1 month momentum -> 1 month beta\n",
    "    'MR2': 'Beta_2M_Winsorized',   # 2 month momentum -> 2 month beta\n",
    "    'MR3': 'Beta_3M_Winsorized',   # 3 month momentum -> 3 month beta\n",
    "    'MR6': 'Beta_6M_Winsorized',   # 6 month momentum -> 6 month beta\n",
    "    'MR12': 'Beta_12M_Winsorized', # 12 month momentum -> 12 month beta\n",
    "}\n",
    "\n",
    "# Check which beta columns are available and create fallback mapping\n",
    "available_beta_cols = [col for col in df.columns if 'Beta_' in col]\n",
    "print(f\"Available beta columns: {available_beta_cols}\")\n",
    "\n",
    "# Create final mapping with fallbacks\n",
    "final_beta_mapping = {}\n",
    "for momentum_label, preferred_beta in momentum_beta_mapping.items():\n",
    "    if preferred_beta in df.columns:\n",
    "        final_beta_mapping[momentum_label] = preferred_beta\n",
    "        print(f\"{momentum_label} -> {preferred_beta} ✓\")\n",
    "    else:\n",
    "        # Try fallback to non-winsorized version\n",
    "        fallback_beta = preferred_beta.replace('_Winsorized', '')\n",
    "        if fallback_beta in df.columns:\n",
    "            final_beta_mapping[momentum_label] = fallback_beta\n",
    "            print(f\"{momentum_label} -> {fallback_beta} (fallback) ✓\")\n",
    "        else:\n",
    "            print(f\"Warning: No suitable beta column found for {momentum_label}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\nFinal momentum-beta mapping:\")\n",
    "for mom, beta in final_beta_mapping.items():\n",
    "    print(f\"  {mom} normalized by {beta}\")\n",
    "\n",
    "# Normalize each momentum ratio by its corresponding beta period\n",
    "print(\"\\nNormalizing momentum ratios by corresponding beta periods...\")\n",
    "\n",
    "for momentum_label in periods.keys():\n",
    "    if momentum_label not in final_beta_mapping:\n",
    "        print(f\"Skipping {momentum_label} - no corresponding beta column available\")\n",
    "        continue\n",
    "    \n",
    "    beta_column = final_beta_mapping[momentum_label]\n",
    "    \n",
    "    # Create a mask for valid beta values (not NaN, not zero, and not too close to zero)\n",
    "    valid_beta_mask = (\n",
    "        df[beta_column].notna() & \n",
    "        (np.abs(df[beta_column]) > 0.01)  # Avoid division by very small numbers\n",
    "    )\n",
    "    \n",
    "    # Initialize normalized momentum column\n",
    "    df[f'{momentum_label}_normalized'] = np.nan\n",
    "    \n",
    "    # Apply normalization only where beta is valid\n",
    "    df.loc[valid_beta_mask, f'{momentum_label}_normalized'] = (\n",
    "        df.loc[valid_beta_mask, momentum_label] / df.loc[valid_beta_mask, beta_column]\n",
    "    )\n",
    "    \n",
    "    # Replace the original column with normalized version\n",
    "    df[momentum_label] = df[f'{momentum_label}_normalized']\n",
    "    df.drop(columns=[f'{momentum_label}_normalized'], inplace=True)\n",
    "    \n",
    "    print(f\"  {momentum_label} normalized by {beta_column}\")\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"Calculating cross-sectional statistics...\")\n",
    "\n",
    "# Calculate the mean and std deviation of each momentum ratio across the universe\n",
    "for label in periods.keys():\n",
    "    df[f'mu_{label}'] = df.groupby('Date')[label].transform(lambda x: x.mean())\n",
    "    df[f'sigma_{label}'] = df.groupby('Date')[label].transform(lambda x: x.std())\n",
    "\n",
    "print(\"Calculating Z-scores...\")\n",
    "\n",
    "# Calculate Z-scores for each period\n",
    "for label in periods.keys():\n",
    "    df[f'Z_{label}'] = (df[label] - df[f'mu_{label}']) / df[f'sigma_{label}']\n",
    "\n",
    "print(\"Filtering to top 500 stocks by market cap...\")\n",
    "\n",
    "# Keep only top 500 by market cap each date\n",
    "df = df.groupby('Date', group_keys=False).apply(\n",
    "    lambda x: x.sort_values(by='Mcap', ascending=False).head(500)\n",
    ")\n",
    "\n",
    "print(\"Calculating combined momentum scores...\")\n",
    "\n",
    "# Define specific combinations as tuples of the labels you want:\n",
    "specific_combinations = [\n",
    "    ('MR1', 'MR2', 'MR3', 'MR6', 'MR12'),  # All periods combined\n",
    "    # You can add more combinations here, e.g.:\n",
    "    # ('MR1', 'MR3'),      # Short-term momentum\n",
    "    # ('MR6', 'MR12'),     # Long-term momentum\n",
    "]\n",
    "\n",
    "# Loop through and compute weighted avg Z-score and normalized momentum:\n",
    "for comb in specific_combinations:\n",
    "    # comb is now something like ('MR1', 'MR2', 'MR3', 'MR6', 'MR12')\n",
    "    comb_labels = [f'Z_{label}' for label in comb]       # e.g. ['Z_MR1', 'Z_MR2', ...]\n",
    "    comb_weights = np.ones(len(comb_labels)) / len(comb_labels)  # Equal weights\n",
    "    comb_name = \"_\".join(comb)                           # e.g. 'MR1_MR2_MR3_MR6_MR12'\n",
    "\n",
    "    # Make sure each f'Z_{label}' is actually a column in df\n",
    "    missing = set(comb_labels) - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"The following Z-columns are missing: {missing}\")\n",
    "\n",
    "    # Weighted average Z-score\n",
    "    df[f'WeightedAvgZ_{comb_name}'] = df[comb_labels].dot(comb_weights)\n",
    "\n",
    "    # Normalized momentum score\n",
    "    df[f'NormalizedMomentumScore_{comb_name}'] = np.where(\n",
    "        df[f'WeightedAvgZ_{comb_name}'] >= 0,\n",
    "        1 + df[f'WeightedAvgZ_{comb_name}'],\n",
    "        (1 - df[f'WeightedAvgZ_{comb_name}']) ** -1\n",
    "    )\n",
    "\n",
    "print(\"Momentum calculation completed with period-specific beta normalization!\")\n",
    "print(\"Note: All momentum ratios were winsorized cross-sectionally (5th-95th percentiles) before beta normalization\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"Number of unique symbols: {df['Symbol'].nunique()}\")\n",
    "print(f\"Processing steps: Momentum calculation → Cross-sectional winsorization → Beta normalization → Z-scores\")\n",
    "\n",
    "# Show momentum columns created\n",
    "momentum_cols = [col for col in df.columns if any(mr in col for mr in periods.keys())]\n",
    "print(f\"\\nMomentum-related columns created: {len(momentum_cols)}\")\n",
    "\n",
    "# Display sample of results\n",
    "print(f\"\\nSample data (last 5 rows):\")\n",
    "sample_cols = ['Date', 'Symbol', 'Mcap'] + list(periods.keys()) + [f'Z_{label}' for label in periods.keys()]\n",
    "available_cols = [col for col in sample_cols if col in df.columns]\n",
    "print(df[available_cols].tail().to_string(index=False))\n",
    "\n",
    "# Show statistics for each momentum ratio\n",
    "print(f\"\\nFinal Momentum Ratio Statistics (Winsorized + Beta-Normalized):\")\n",
    "print(\"=\" * 70)\n",
    "for momentum_label in periods.keys():\n",
    "    if momentum_label in df.columns and momentum_label in final_beta_mapping:\n",
    "        beta_used = final_beta_mapping[momentum_label]\n",
    "        valid_data = df[momentum_label].dropna()\n",
    "        if len(valid_data) > 0:\n",
    "            print(f\"\\n{momentum_label} (winsorized, then normalized by {beta_used}):\")\n",
    "            print(f\"  Count: {len(valid_data):,}\")\n",
    "            print(f\"  Mean: {valid_data.mean():.4f}\")\n",
    "            print(f\"  Std: {valid_data.std():.4f}\")\n",
    "            print(f\"  Min: {valid_data.min():.4f}\")\n",
    "            print(f\"  Max: {valid_data.max():.4f}\")\n",
    "            print(f\"  25th percentile: {valid_data.quantile(0.25):.4f}\")\n",
    "            print(f\"  75th percentile: {valid_data.quantile(0.75):.4f}\")\n",
    "\n",
    "# Show the normalization summary\n",
    "print(f\"\\nFinal Processing Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for momentum_label, beta_col in final_beta_mapping.items():\n",
    "    period_days = periods[momentum_label]\n",
    "    valid_count = df[momentum_label].notna().sum()\n",
    "    total_count = len(df)\n",
    "    print(f\"{momentum_label} ({period_days} days): Winsorized → {beta_col} normalized | Valid: {valid_count:,}/{total_count:,} ({valid_count/total_count*100:.1f}%)\")\n",
    "\n",
    "# Show final combined scores\n",
    "final_score_cols = [col for col in df.columns if 'NormalizedMomentumScore_' in col]\n",
    "if final_score_cols:\n",
    "    print(f\"\\nFinal Normalized Momentum Score columns:\")\n",
    "    for col in final_score_cols:\n",
    "        print(f\"  {col}\")\n",
    "        valid_scores = df[col].dropna()\n",
    "        if len(valid_scores) > 0:\n",
    "            print(f\"    Range: [{valid_scores.min():.4f}, {valid_scores.max():.4f}]\")\n",
    "            print(f\"    Mean: {valid_scores.mean():.4f}\")\n",
    "\n",
    "print(\"\\nData is ready for further analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e4bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating momentum ratios...\n",
      "Available beta columns: ['Beta_1M', 'Beta_2M', 'Beta_3M', 'Beta_6M', 'Beta_12M', 'Beta_1M_Winsorized', 'Beta_2M_Winsorized', 'Beta_3M_Winsorized', 'Beta_6M_Winsorized', 'Beta_12M_Winsorized']\n",
      "MR1 -> Beta_1M_Winsorized ✓\n",
      "MR2 -> Beta_2M_Winsorized ✓\n",
      "MR3 -> Beta_3M_Winsorized ✓\n",
      "MR6 -> Beta_6M_Winsorized ✓\n",
      "MR12 -> Beta_12M_Winsorized ✓\n",
      "\n",
      "Final momentum-beta mapping:\n",
      "  MR1 normalized by Beta_1M_Winsorized\n",
      "  MR2 normalized by Beta_2M_Winsorized\n",
      "  MR3 normalized by Beta_3M_Winsorized\n",
      "  MR6 normalized by Beta_6M_Winsorized\n",
      "  MR12 normalized by Beta_12M_Winsorized\n",
      "\n",
      "Normalizing momentum ratios by corresponding beta periods...\n",
      "  MR1 normalized by Beta_1M_Winsorized\n",
      "  MR2 normalized by Beta_2M_Winsorized\n",
      "  MR3 normalized by Beta_3M_Winsorized\n",
      "  MR6 normalized by Beta_6M_Winsorized\n",
      "  MR12 normalized by Beta_12M_Winsorized\n",
      "Calculating cross-sectional statistics...\n",
      "Calculating Z-scores...\n",
      "Filtering to top 500 stocks by market cap...\n",
      "Calculating combined momentum scores...\n",
      "Momentum calculation completed with period-specific beta normalization!\n",
      "\n",
      "Summary Statistics:\n",
      "Dataset shape: (2267971, 54)\n",
      "Date range: 2007-01-09 00:00:00 to 2025-06-06 00:00:00\n",
      "Number of unique symbols: 1244\n",
      "Normalization approach: Period-specific beta matching\n",
      "\n",
      "Momentum-related columns created: 22\n",
      "\n",
      "Sample data (last 5 rows):\n",
      "      Date     Symbol         Mcap       MR1       MR2       MR3       MR6      MR12     Z_MR1     Z_MR2     Z_MR3     Z_MR6    Z_MR12\n",
      "2025-06-06 BECTORFOOD 86055.603590 -0.011946 -0.056376  0.056602 -0.105683  0.200153 -0.116437 -0.144162 -0.091283 -0.054178 -0.034496\n",
      "2025-06-06 GANESHHOUC 85705.251102 -0.062053 -0.022388 -0.108438 -0.016423  0.266298 -0.154125 -0.130030 -0.187032 -0.040377 -0.023251\n",
      "2025-06-06 METROPOLIS 85587.066136  0.023425  0.019873  0.002641 -0.142090 -0.027410 -0.089833 -0.112458 -0.122589 -0.059807 -0.073183\n",
      "2025-06-06       CERA 85246.297239  0.281375  0.162998  0.150194 -0.093680 -0.087986  0.104184 -0.052949 -0.036986 -0.052322 -0.083481\n",
      "2025-06-06       KRBL 85215.706792  3.439978  0.673001  0.639944  0.618086  0.441489  2.479931  0.159104  0.247144  0.057725  0.006533\n",
      "\n",
      "Momentum Ratio Statistics (Period-Specific Beta Normalization):\n",
      "======================================================================\n",
      "\n",
      "MR1 (normalized by Beta_1M_Winsorized):\n",
      "  Count: 2,234,425\n",
      "  Mean: 0.0242\n",
      "  Std: 1.0665\n",
      "  Min: -121.3309\n",
      "  Max: 167.2142\n",
      "  25th percentile: -0.0655\n",
      "  75th percentile: 0.0943\n",
      "\n",
      "MR2 (normalized by Beta_2M_Winsorized):\n",
      "  Count: 2,216,801\n",
      "  Mean: 0.0656\n",
      "  Std: 1.4064\n",
      "  Min: -272.7101\n",
      "  Max: 257.4067\n",
      "  25th percentile: -0.0858\n",
      "  75th percentile: 0.1536\n",
      "\n",
      "MR3 (normalized by Beta_3M_Winsorized):\n",
      "  Count: 2,199,550\n",
      "  Mean: 0.1046\n",
      "  Std: 1.7709\n",
      "  Min: -160.4047\n",
      "  Max: 1368.3993\n",
      "  25th percentile: -0.1003\n",
      "  75th percentile: 0.2018\n",
      "\n",
      "MR6 (normalized by Beta_6M_Winsorized):\n",
      "  Count: 2,139,115\n",
      "  Mean: 0.2445\n",
      "  Std: 4.5812\n",
      "  Min: -391.6925\n",
      "  Max: 2356.6838\n",
      "  25th percentile: -0.1281\n",
      "  75th percentile: 0.3486\n",
      "\n",
      "MR12 (normalized by Beta_12M_Winsorized):\n",
      "  Count: 2,022,898\n",
      "  Mean: 0.5084\n",
      "  Std: 8.9522\n",
      "  Min: -15.0710\n",
      "  Max: 4749.3100\n",
      "  25th percentile: -0.1501\n",
      "  75th percentile: 0.6245\n",
      "\n",
      "Normalization Summary:\n",
      "==================================================\n",
      "MR1 (21 days): Beta_1M_Winsorized | Valid: 2,234,425/2,267,971 (98.5%)\n",
      "MR2 (42 days): Beta_2M_Winsorized | Valid: 2,216,801/2,267,971 (97.7%)\n",
      "MR3 (63 days): Beta_3M_Winsorized | Valid: 2,199,550/2,267,971 (97.0%)\n",
      "MR6 (126 days): Beta_6M_Winsorized | Valid: 2,139,115/2,267,971 (94.3%)\n",
      "MR12 (252 days): Beta_12M_Winsorized | Valid: 2,022,898/2,267,971 (89.2%)\n",
      "\n",
      "Final Normalized Momentum Score columns:\n",
      "  NormalizedMomentumScore_MR1_MR2_MR3_MR6_MR12\n",
      "    Range: [0.0700, 29.0858]\n",
      "    Mean: 1.0636\n",
      "\n",
      "Data is ready for further analysis!\n"
     ]
    }
   ],
   "source": [
    "# # Function to calculate log returns\n",
    "# def calculate_log_returns(df):\n",
    "#     df['LogReturn'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "#     return df.dropna()\n",
    "\n",
    "# # Function to calculate momentum ratios\n",
    "# def calculate_momentum_ratios(series, period):\n",
    "#     return series / series.shift(period) - 1\n",
    "\n",
    "# # Define periods for momentum ratios (in trading days)\n",
    "# periods = {\n",
    "#     'MR1': 21,   # 1 month\n",
    "#     'MR2': 42,   # 2 months\n",
    "#     'MR3': 63,   # 3 months\n",
    "#     'MR6': 126,  # 6 months\n",
    "#     'MR12': 252, # 12 months\n",
    "# }\n",
    "\n",
    "# # Apply log return calculation\n",
    "# df = df.groupby('Symbol', group_keys=False).apply(calculate_log_returns)\n",
    "\n",
    "# # Calculate momentum ratios for each period\n",
    "# print(\"Calculating momentum ratios...\")\n",
    "# for label, period in periods.items():\n",
    "#     df[label] = df.groupby('Symbol')['Close'].transform(lambda x: calculate_momentum_ratios(x, period))\n",
    "\n",
    "# # Define mapping between momentum periods and corresponding beta columns\n",
    "# momentum_beta_mapping = {\n",
    "#     'MR1': 'Beta_1M_Winsorized',   # 1 month momentum -> 1 month beta\n",
    "#     'MR2': 'Beta_2M_Winsorized',   # 2 month momentum -> 2 month beta\n",
    "#     'MR3': 'Beta_3M_Winsorized',   # 3 month momentum -> 3 month beta\n",
    "#     'MR6': 'Beta_6M_Winsorized',   # 6 month momentum -> 6 month beta\n",
    "#     'MR12': 'Beta_12M_Winsorized', # 12 month momentum -> 12 month beta\n",
    "# }\n",
    "\n",
    "# # Check which beta columns are available and create fallback mapping\n",
    "# available_beta_cols = [col for col in df.columns if 'Beta_' in col]\n",
    "# print(f\"Available beta columns: {available_beta_cols}\")\n",
    "\n",
    "# # Create final mapping with fallbacks\n",
    "# final_beta_mapping = {}\n",
    "# for momentum_label, preferred_beta in momentum_beta_mapping.items():\n",
    "#     if preferred_beta in df.columns:\n",
    "#         final_beta_mapping[momentum_label] = preferred_beta\n",
    "#         print(f\"{momentum_label} -> {preferred_beta} ✓\")\n",
    "#     else:\n",
    "#         # Try fallback to non-winsorized version\n",
    "#         fallback_beta = preferred_beta.replace('_Winsorized', '')\n",
    "#         if fallback_beta in df.columns:\n",
    "#             final_beta_mapping[momentum_label] = fallback_beta\n",
    "#             print(f\"{momentum_label} -> {fallback_beta} (fallback) ✓\")\n",
    "#         else:\n",
    "#             print(f\"Warning: No suitable beta column found for {momentum_label}\")\n",
    "#             continue\n",
    "\n",
    "# print(f\"\\nFinal momentum-beta mapping:\")\n",
    "# for mom, beta in final_beta_mapping.items():\n",
    "#     print(f\"  {mom} normalized by {beta}\")\n",
    "\n",
    "# # Normalize each momentum ratio by its corresponding beta period\n",
    "# print(\"\\nNormalizing momentum ratios by corresponding beta periods...\")\n",
    "\n",
    "# for momentum_label in periods.keys():\n",
    "#     if momentum_label not in final_beta_mapping:\n",
    "#         print(f\"Skipping {momentum_label} - no corresponding beta column available\")\n",
    "#         continue\n",
    "    \n",
    "#     beta_column = final_beta_mapping[momentum_label]\n",
    "    \n",
    "#     # Create a mask for valid beta values (not NaN, not zero, and not too close to zero)\n",
    "#     valid_beta_mask = (\n",
    "#         df[beta_column].notna() & \n",
    "#         (np.abs(df[beta_column]) > 0.01)  # Avoid division by very small numbers\n",
    "#     )\n",
    "    \n",
    "#     # Initialize normalized momentum column\n",
    "#     df[f'{momentum_label}_normalized'] = np.nan\n",
    "    \n",
    "#     # Apply normalization only where beta is valid\n",
    "#     df.loc[valid_beta_mask, f'{momentum_label}_normalized'] = (\n",
    "#         df.loc[valid_beta_mask, momentum_label] / df.loc[valid_beta_mask, beta_column]\n",
    "#     )\n",
    "    \n",
    "#     # Replace the original column with normalized version\n",
    "#     df[momentum_label] = df[f'{momentum_label}_normalized']\n",
    "#     df.drop(columns=[f'{momentum_label}_normalized'], inplace=True)\n",
    "    \n",
    "#     print(f\"  {momentum_label} normalized by {beta_column}\")\n",
    "\n",
    "# # Reset index\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "# print(\"Calculating cross-sectional statistics...\")\n",
    "\n",
    "# # Calculate the mean and std deviation of each momentum ratio across the universe\n",
    "# for label in periods.keys():\n",
    "#     df[f'mu_{label}'] = df.groupby('Date')[label].transform(lambda x: x.mean())\n",
    "#     df[f'sigma_{label}'] = df.groupby('Date')[label].transform(lambda x: x.std())\n",
    "\n",
    "# print(\"Calculating Z-scores...\")\n",
    "\n",
    "# # Calculate Z-scores for each period\n",
    "# for label in periods.keys():\n",
    "#     df[f'Z_{label}'] = (df[label] - df[f'mu_{label}']) / df[f'sigma_{label}']\n",
    "\n",
    "# print(\"Filtering to top 500 stocks by market cap...\")\n",
    "\n",
    "# # Keep only top 500 by market cap each date\n",
    "# df = df.groupby('Date', group_keys=False).apply(\n",
    "#     lambda x: x.sort_values(by='Mcap', ascending=False).head(500)\n",
    "# )\n",
    "\n",
    "# print(\"Calculating combined momentum scores...\")\n",
    "\n",
    "# # Define specific combinations as tuples of the labels you want:\n",
    "# specific_combinations = [\n",
    "#     ('MR1', 'MR2', 'MR3', 'MR6', 'MR12'),  # All periods combined\n",
    "#     # You can add more combinations here, e.g.:\n",
    "#     # ('MR1', 'MR3'),      # Short-term momentum\n",
    "#     # ('MR6', 'MR12'),     # Long-term momentum\n",
    "# ]\n",
    "\n",
    "# # Loop through and compute weighted avg Z-score and normalized momentum:\n",
    "# for comb in specific_combinations:\n",
    "#     # comb is now something like ('MR1', 'MR2', 'MR3', 'MR6', 'MR12')\n",
    "#     comb_labels = [f'Z_{label}' for label in comb]       # e.g. ['Z_MR1', 'Z_MR2', ...]\n",
    "#     comb_weights = np.ones(len(comb_labels)) / len(comb_labels)  # Equal weights\n",
    "#     comb_name = \"_\".join(comb)                           # e.g. 'MR1_MR2_MR3_MR6_MR12'\n",
    "\n",
    "#     # Make sure each f'Z_{label}' is actually a column in df\n",
    "#     missing = set(comb_labels) - set(df.columns)\n",
    "#     if missing:\n",
    "#         raise KeyError(f\"The following Z-columns are missing: {missing}\")\n",
    "\n",
    "#     # Weighted average Z-score\n",
    "#     df[f'WeightedAvgZ_{comb_name}'] = df[comb_labels].dot(comb_weights)\n",
    "\n",
    "#     # Normalized momentum score\n",
    "#     df[f'NormalizedMomentumScore_{comb_name}'] = np.where(\n",
    "#         df[f'WeightedAvgZ_{comb_name}'] >= 0,\n",
    "#         1 + df[f'WeightedAvgZ_{comb_name}'],\n",
    "#         (1 - df[f'WeightedAvgZ_{comb_name}']) ** -1\n",
    "#     )\n",
    "\n",
    "# print(\"Momentum calculation completed with period-specific beta normalization!\")\n",
    "\n",
    "# # Display summary statistics\n",
    "# print(\"\\nSummary Statistics:\")\n",
    "# print(f\"Dataset shape: {df.shape}\")\n",
    "# print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "# print(f\"Number of unique symbols: {df['Symbol'].nunique()}\")\n",
    "# print(f\"Normalization approach: Period-specific beta matching\")\n",
    "\n",
    "# # Show momentum columns created\n",
    "# momentum_cols = [col for col in df.columns if any(mr in col for mr in periods.keys())]\n",
    "# print(f\"\\nMomentum-related columns created: {len(momentum_cols)}\")\n",
    "\n",
    "# # Display sample of results\n",
    "# print(f\"\\nSample data (last 5 rows):\")\n",
    "# sample_cols = ['Date', 'Symbol', 'Mcap'] + list(periods.keys()) + [f'Z_{label}' for label in periods.keys()]\n",
    "# available_cols = [col for col in sample_cols if col in df.columns]\n",
    "# print(df[available_cols].tail().to_string(index=False))\n",
    "\n",
    "# # Show statistics for each momentum ratio\n",
    "# print(f\"\\nMomentum Ratio Statistics (Period-Specific Beta Normalization):\")\n",
    "# print(\"=\" * 70)\n",
    "# for momentum_label in periods.keys():\n",
    "#     if momentum_label in df.columns and momentum_label in final_beta_mapping:\n",
    "#         beta_used = final_beta_mapping[momentum_label]\n",
    "#         valid_data = df[momentum_label].dropna()\n",
    "#         if len(valid_data) > 0:\n",
    "#             print(f\"\\n{momentum_label} (normalized by {beta_used}):\")\n",
    "#             print(f\"  Count: {len(valid_data):,}\")\n",
    "#             print(f\"  Mean: {valid_data.mean():.4f}\")\n",
    "#             print(f\"  Std: {valid_data.std():.4f}\")\n",
    "#             print(f\"  Min: {valid_data.min():.4f}\")\n",
    "#             print(f\"  Max: {valid_data.max():.4f}\")\n",
    "#             print(f\"  25th percentile: {valid_data.quantile(0.25):.4f}\")\n",
    "#             print(f\"  75th percentile: {valid_data.quantile(0.75):.4f}\")\n",
    "\n",
    "# # Show the normalization summary\n",
    "# print(f\"\\nNormalization Summary:\")\n",
    "# print(\"=\" * 50)\n",
    "# for momentum_label, beta_col in final_beta_mapping.items():\n",
    "#     period_days = periods[momentum_label]\n",
    "#     valid_count = df[momentum_label].notna().sum()\n",
    "#     total_count = len(df)\n",
    "#     print(f\"{momentum_label} ({period_days} days): {beta_col} | Valid: {valid_count:,}/{total_count:,} ({valid_count/total_count*100:.1f}%)\")\n",
    "\n",
    "# # Show final combined scores\n",
    "# final_score_cols = [col for col in df.columns if 'NormalizedMomentumScore_' in col]\n",
    "# if final_score_cols:\n",
    "#     print(f\"\\nFinal Normalized Momentum Score columns:\")\n",
    "#     for col in final_score_cols:\n",
    "#         print(f\"  {col}\")\n",
    "#         valid_scores = df[col].dropna()\n",
    "#         if len(valid_scores) > 0:\n",
    "#             print(f\"    Range: [{valid_scores.min():.4f}, {valid_scores.max():.4f}]\")\n",
    "#             print(f\"    Mean: {valid_scores.mean():.4f}\")\n",
    "\n",
    "# print(\"\\nData is ready for further analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3b11c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the required columns: Date, Symbol, and all columns containing 'NormalizedMomentumScore'\n",
    "columns_to_keep = ['Date', 'Symbol'] + [col for col in df.columns if 'NormalizedMomentumScore' in col]\n",
    "\n",
    "# Create the new DataFrame with the selected columns\n",
    "final_df = df[columns_to_keep]\n",
    "\n",
    "# Rename the 'NormalizedMomentumScore' columns to 'MoM1', 'MoM2', 'MoM3', etc.\n",
    "normalized_columns = [col for col in final_df.columns if 'NormalizedMomentumScore' in col]\n",
    "rename_dict = {col: f'MoMMulti' for i, col in enumerate(normalized_columns)}\n",
    "\n",
    "# Apply the renaming\n",
    "final_df.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d4767d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date      Symbol  MoMMulti\n",
      "0      2007-01-09        HEXT  3.050060\n",
      "1      2007-01-09   KIRLOSIND  2.970796\n",
      "2      2007-01-09  INDIABULLS  2.911743\n",
      "3      2007-01-09        HOCL  2.760109\n",
      "4      2007-01-09        IIFL  2.587121\n",
      "...           ...         ...       ...\n",
      "226795 2025-06-06  VINATIORGA  1.449196\n",
      "226796 2025-06-06        IIFL  1.422792\n",
      "226797 2025-06-06        IFCI  1.416606\n",
      "226798 2025-06-06       HUDCO  1.408857\n",
      "226799 2025-06-06        JLHL  1.395694\n",
      "\n",
      "[226800 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# === Select Top 25 per Date by final weighted score ===\n",
    "top_25 = (\n",
    "    final_df[['Date', 'Symbol', 'MoMMulti']]\n",
    "      .sort_values(['Date', 'MoMMulti'], ascending=[True, False])\n",
    "      .groupby('Date')\n",
    "      .head(50)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# === Output Top 25 ===\n",
    "print(top_25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfe55fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_date = price_data.drop_duplicates(subset='Date')[['Date']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c766e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start date (it should start from 2006-06-19)\n",
    "start_date = pd.to_datetime('2007-01-09')\n",
    "\n",
    "# Filter the dates starting from 2006-06-19 (this ensures the start date is included)\n",
    "filtered_dates = master_date[master_date['Date'] >= start_date]\n",
    "\n",
    "# Ensure the start date is included\n",
    "start_date_row = filtered_dates[filtered_dates['Date'] == start_date]\n",
    "\n",
    "# Select every 50th date from the filtered dates (starting from the filtered list after the start date)\n",
    "selected_dates = filtered_dates.iloc[::44]\n",
    "\n",
    "# Combine the start date with the selected dates\n",
    "selected_dates = pd.concat([start_date_row, selected_dates])\n",
    "\n",
    "# Drop any NaN values and sort by date to ensure it's in the correct order\n",
    "selected_dates = selected_dates.dropna().sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebf1b7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>MoMMulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>HEXT</td>\n",
       "      <td>3.050060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>KIRLOSIND</td>\n",
       "      <td>2.970796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>INDIABULLS</td>\n",
       "      <td>2.911743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>HOCL</td>\n",
       "      <td>2.760109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>IIFL</td>\n",
       "      <td>2.587121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226395</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>HINDALCO</td>\n",
       "      <td>1.321052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226396</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>GLENMARK</td>\n",
       "      <td>1.320118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226397</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>BSOFT</td>\n",
       "      <td>1.319239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226398</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>CESC</td>\n",
       "      <td>1.309101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226399</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>DCMSHRIRAM</td>\n",
       "      <td>1.306198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date      Symbol  MoMMulti\n",
       "0       2007-01-09        HEXT  3.050060\n",
       "1       2007-01-09   KIRLOSIND  2.970796\n",
       "2       2007-01-09  INDIABULLS  2.911743\n",
       "3       2007-01-09        HOCL  2.760109\n",
       "4       2007-01-09        IIFL  2.587121\n",
       "...            ...         ...       ...\n",
       "226395  2025-05-27    HINDALCO  1.321052\n",
       "226396  2025-05-27    GLENMARK  1.320118\n",
       "226397  2025-05-27       BSOFT  1.319239\n",
       "226398  2025-05-27        CESC  1.309101\n",
       "226399  2025-05-27  DCMSHRIRAM  1.306198\n",
       "\n",
       "[5200 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Ensure both are datetime.date\n",
    "top_25['Date'] = pd.to_datetime(top_25['Date']).dt.date\n",
    "selected_dates['Date'] = pd.to_datetime(selected_dates['Date']).dt.date\n",
    "\n",
    "# Step 2: Get the list of unique dates\n",
    "date_list = selected_dates['Date'].unique()\n",
    "\n",
    "# Step 3: Filter\n",
    "filtered_df = top_25[top_25['Date'].isin(date_list)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57af4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('BetaAdjMom.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820cd85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
