{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import os\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Fincode', 'Result_Type', 'NoOfMonths', 'Date_End', 'NET_SALES',\n",
      "       'INT_ADV', 'INC_INV', 'INT_BAL', 'INT_OTHERS', 'OTHER_INCOME',\n",
      "       ...\n",
      "       'exc_foreign_exch_gain', 'exc_other', 'Curr_tax', 'Def_tax',\n",
      "       'Fringe_benefits', 'Prior_Period_Tax', 'Mat_Credit', 'Other_Tax',\n",
      "       'flag', 'notes'],\n",
      "      dtype='object', length=132)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fincode</th>\n",
       "      <th>Result_Type</th>\n",
       "      <th>NoOfMonths</th>\n",
       "      <th>Date_End</th>\n",
       "      <th>NET_SALES</th>\n",
       "      <th>INT_ADV</th>\n",
       "      <th>INC_INV</th>\n",
       "      <th>INT_BAL</th>\n",
       "      <th>INT_OTHERS</th>\n",
       "      <th>OTHER_INCOME</th>\n",
       "      <th>...</th>\n",
       "      <th>exc_foreign_exch_gain</th>\n",
       "      <th>exc_other</th>\n",
       "      <th>Curr_tax</th>\n",
       "      <th>Def_tax</th>\n",
       "      <th>Fringe_benefits</th>\n",
       "      <th>Prior_Period_Tax</th>\n",
       "      <th>Mat_Credit</th>\n",
       "      <th>Other_Tax</th>\n",
       "      <th>flag</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>100002</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>200003</td>\n",
       "      <td>1491.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>100002</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>200006</td>\n",
       "      <td>1648.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>100002</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>200009</td>\n",
       "      <td>1935.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100002</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>200012</td>\n",
       "      <td>2860.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100002</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>200103</td>\n",
       "      <td>2021.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925157</th>\n",
       "      <td>317142</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>202409</td>\n",
       "      <td>510.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925159</th>\n",
       "      <td>317635</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>202412</td>\n",
       "      <td>13920.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>477.10</td>\n",
       "      <td>-32.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925163</th>\n",
       "      <td>318188</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>202409</td>\n",
       "      <td>679.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925164</th>\n",
       "      <td>318188</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>202412</td>\n",
       "      <td>3367.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1005.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925168</th>\n",
       "      <td>318678</td>\n",
       "      <td>Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>202412</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333533 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fincode Result_Type  NoOfMonths  Date_End  NET_SALES  INT_ADV  \\\n",
       "96       100002           Q         3.0    200003    1491.10      0.0   \n",
       "97       100002           Q         3.0    200006    1648.37      0.0   \n",
       "98       100002           Q         3.0    200009    1935.69      0.0   \n",
       "99       100002           Q         3.0    200012    2860.59      0.0   \n",
       "100      100002           Q         3.0    200103    2021.72      0.0   \n",
       "...         ...         ...         ...       ...        ...      ...   \n",
       "925157   317142           Q         3.0    202409     510.91      0.0   \n",
       "925159   317635           Q         3.0    202412   13920.09      0.0   \n",
       "925163   318188           Q         3.0    202409     679.80      0.0   \n",
       "925164   318188           Q         3.0    202412    3367.49      0.0   \n",
       "925168   318678           Q         3.0    202412       0.00      0.0   \n",
       "\n",
       "        INC_INV  INT_BAL  INT_OTHERS  OTHER_INCOME  ...  \\\n",
       "96          0.0      0.0         0.0         25.90  ...   \n",
       "97          0.0      0.0         0.0         49.47  ...   \n",
       "98          0.0      0.0         0.0         11.27  ...   \n",
       "99          0.0      0.0         0.0         48.83  ...   \n",
       "100         0.0      0.0         0.0         18.45  ...   \n",
       "...         ...      ...         ...           ...  ...   \n",
       "925157      0.0      0.0         0.0          2.60  ...   \n",
       "925159      0.0      0.0         0.0        166.66  ...   \n",
       "925163      0.0      0.0         0.0          5.84  ...   \n",
       "925164      0.0      0.0         0.0         50.14  ...   \n",
       "925168      0.0      0.0         0.0         16.39  ...   \n",
       "\n",
       "        exc_foreign_exch_gain  exc_other  Curr_tax  Def_tax  Fringe_benefits  \\\n",
       "96                        0.0       0.00      0.00     0.00              0.0   \n",
       "97                        0.0       0.00      8.00     0.00              0.0   \n",
       "98                        0.0       0.00     62.00     0.00              0.0   \n",
       "99                        0.0       0.00     95.00     0.00              0.0   \n",
       "100                       0.0       0.00     13.00     0.00              0.0   \n",
       "...                       ...        ...       ...      ...              ...   \n",
       "925157                    0.0       0.00      0.00     0.15              0.0   \n",
       "925159                    0.0       0.00    477.10   -32.14              0.0   \n",
       "925163                    0.0      -9.54      0.00     0.00              0.0   \n",
       "925164                    0.0   -1005.23      0.00     0.00              0.0   \n",
       "925168                    0.0       0.00      1.92     0.58              0.0   \n",
       "\n",
       "        Prior_Period_Tax  Mat_Credit  Other_Tax  flag  notes  \n",
       "96                   0.0         0.0        0.0     A    NaN  \n",
       "97                   0.0         0.0        0.0     A    NaN  \n",
       "98                   0.0         0.0        0.0     A    NaN  \n",
       "99                   0.0         0.0        0.0     A    NaN  \n",
       "100                  0.0         0.0        0.0     A    NaN  \n",
       "...                  ...         ...        ...   ...    ...  \n",
       "925157               0.0         0.0        0.0     A    NaN  \n",
       "925159               0.0         0.0        0.0     A    NaN  \n",
       "925163               0.0         0.0        0.0     A    NaN  \n",
       "925164               0.0         0.0        0.0     A    NaN  \n",
       "925168               0.0         0.0        0.0     A    NaN  \n",
       "\n",
       "[333533 rows x 132 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_excel(\"company_master_mapping.xlsx\")\n",
    "# price_data = d.fetch_price_data(no_of_years=20)\n",
    "price_data = pd.read_csv('stockPriceData.csv')\n",
    "# Convert 'Date' to datetime type\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'])\n",
    "\n",
    "# Create a dictionary mapping from SYMBOL_NSE to SYMBOL_CM\n",
    "mapping = dict(zip(mapping[\"SYMBOL_NSE\"], mapping[\"SYMBOL_CM\"]))\n",
    "price_data[\"Symbol\"] = price_data[\"Symbol\"].replace(mapping)\n",
    "\n",
    "top_500 =  price_data.groupby('Date', group_keys= False).apply(lambda x: x.sort_values(by='Mcap', ascending=False).head(500))\n",
    "# Filter price data for dates after '2006-01-01' and drop duplicates\n",
    "price_data.drop_duplicates(['Date', 'Symbol'], inplace=True)\n",
    "\n",
    "#company master swapping\n",
    "# company_master = d.fetch_data_from_database(table_name='Companymaster')\n",
    "company_master = pd.read_csv('Companymaster_3_2_2025.csv')\n",
    "company_master[\"SYMBOL\"] = company_master[\"SYMBOL\"].replace(mapping)\n",
    "\n",
    "yearly = pd.read_csv('Finance_pl_3_2_2025.csv')\n",
    "Quaterly = pd.read_csv('Quarterly_3_2_2025.csv')\n",
    "Finance_bs =  pd.read_csv('Finance_bs_3_2_2025.csv')[[ 'Year_end', 'Fincode', 'Share_Capital', 'Reserve']]\n",
    "\n",
    "rebal_dates = pd.read_csv('GrowthDate.csv')\n",
    "\n",
    "rebal_dates[\"Date\"] = pd.to_datetime(rebal_dates[\"Date\"])\n",
    "rebal=rebal_dates['Date']\n",
    "\n",
    "Rebalance_Qtr=list(rebal_dates['Quarter'])\n",
    "Rebalance_Date=list(rebal_dates['Date'])\n",
    "Qtr_date_dict=dict(zip(Rebalance_Date,Rebalance_Qtr))\n",
    "date_Qtr_dict=dict(zip(Rebalance_Qtr,Rebalance_Date))\n",
    "top_500['Quarter']=top_500['Date'].map(Qtr_date_dict)\n",
    "index_constituents_data= top_500\n",
    "\n",
    "X = Quaterly[Quaterly['Result_Type'] == 'Q']\n",
    "print(X.columns)\n",
    "X\n",
    "# # yearly.to_csv('yearly.csv')\n",
    "# # Quaterly.to_csv('Quaterly.csv')\n",
    "# # Finance_bs.to_csv('Finance_bs.csv')\n",
    "# # company_master.to_csv('Companymaster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_master = pd.read_csv('Companymaster.csv')\n",
    "# yearly = pd.read_csv('yearly.csv')\n",
    "# Quaterly = pd.read_csv('Quaterly.csv')\n",
    "# Finance_bs = pd.read_csv('Finance_bs.csv')\n",
    "# price_data = pd.read_csv('price_data.csv')\n",
    "# top_500 =  price_data.groupby('Date', group_keys= False).apply(lambda x: x.sort_values(by='Mcap', ascending=False).head(500))\n",
    "\n",
    "# rebal_dates = pd.read_csv('./RebalanceDate.csv')\n",
    "# rebal_dates[\"Date\"] = pd.to_datetime(rebal_dates[\"Date\"])\n",
    "# rebal=rebal_dates['Date']\n",
    "\n",
    "# Rebalance_Qtr=list(rebal_dates['Quarter'])\n",
    "# Rebalance_Date=list(rebal_dates['Date'])\n",
    "# Qtr_date_dict=dict(zip(Rebalance_Date,Rebalance_Qtr))/\n",
    "# date_Qtr_dict=dict(zip(Rebalance_Qtr,Rebalance_Date))\n",
    "# top_500['Quarter']=top_500['Date'].map(Qtr_date_dict)\n",
    "# index_constituents_data= top_500\n",
    "\n",
    "# X = Quaterly[Quaterly['Result_Type'] == 'Q']\n",
    "# print(X.columns)\n",
    "# X.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Networth \n",
    "Finance_bs['NetWorth'] = Finance_bs['Share_Capital'] + Finance_bs['Reserve']\n",
    "Finance_bs2 = Finance_bs[['Year_end', 'Fincode', 'NetWorth']]\n",
    "Finance_bs3 = pd.merge(Finance_bs2, company_master[['FINCODE', 'SYMBOL']], left_on='Fincode', right_on='FINCODE')\n",
    "Finance_bs3 = Finance_bs3[['Year_end', 'FINCODE', 'SYMBOL', 'NetWorth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisd PAT in units\n",
    "pat_df= X[['Date_End', 'Fincode', 'PAT']]\n",
    "pat_df['PAT'] = pat_df['PAT']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculating Networth on quarterly basis\n",
    "p =pd.merge(pat_df, Finance_bs3, left_on=['Date_End','Fincode'], right_on=['Year_end','FINCODE'], how='left')\n",
    "p['SYMBOL'] = p.groupby('Fincode', group_keys=False)['SYMBOL'].apply(lambda x: x.fillna(method='ffill'))\n",
    "p = p.drop(columns=['Year_end', 'FINCODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarterly Networth Calculation\n",
    "def fill_networth(row, prev_networth):\n",
    "    if pd.isna(row['NetWorth']):\n",
    "        return prev_networth + row['PAT']\n",
    "    else:\n",
    "        return row['NetWorth']\n",
    "\n",
    "def fill_networth_column(df):\n",
    "    df = df.sort_values(by=['Fincode', 'Date_End']) \n",
    "    df['NetWorth_Filled'] = np.nan\n",
    "    \n",
    "    for fincode in df['Fincode'].unique():\n",
    "        prev_networth = None\n",
    "        for i, row in df[df['Fincode'] == fincode].iterrows():\n",
    "            if prev_networth is None:\n",
    "                prev_networth = row['NetWorth']\n",
    "            else:\n",
    "                df.at[i, 'NetWorth_Filled'] = fill_networth(row, prev_networth)\n",
    "                prev_networth = df.at[i, 'NetWorth_Filled']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "p = fill_networth_column(p)\n",
    "\n",
    "# Fill any remaining NaN in the original NetWorth column with the filled values\n",
    "p['NetWorth'] = p['NetWorth'].combine_first(p['NetWorth_Filled'])\n",
    "p.drop(columns=['NetWorth_Filled'], inplace=True)\n",
    "p = p.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating ROE from scratch\n",
    "p['ROE'] = p.groupby('SYMBOL', group_keys=False).apply(lambda x: x['PAT']/x['NetWorth'])\n",
    "p['ROE_ttm'] = p.groupby('SYMBOL', group_keys=False)['ROE'].apply(lambda x: x.rolling(window=4).sum())\n",
    "roe_ttm = p[['Fincode', 'Date_End', 'ROE_ttm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.to_csv('ROEdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opm_df = X[['Fincode', 'Date_End', 'OPERATING_PROFIT', 'NET_SALES']]\n",
    "\n",
    "# opm_df2 = pd.merge(opm_df, company_master[['FINCODE', 'SYMBOL']], left_on='Fincode', right_on='FINCODE')\n",
    "# opm_df2['OPM'] = opm_df2.groupby('SYMBOL', group_keys=False).apply(lambda x: x['OPERATING_PROFIT'].div(x['NET_SALES']))\n",
    "# opm_df2['5Y_OPM_mean'] = opm_df2.groupby('SYMBOL')['OPM'].transform(lambda x : x.rolling(20).mean())\n",
    "# opm_df3 = opm_df2[['Date_End', 'Fincode', '5Y_OPM_mean']].dropna()\n",
    "# opm_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpm_df = X[['Fincode', 'Date_End', 'GROSS_PROFIT', 'NET_SALES','NIM']]\n",
    "# gpm_df2 = pd.merge(gpm_df, company_master[['FINCODE', 'SYMBOL']], left_on='Fincode', right_on='FINCODE')\n",
    "# gpm_df2['GPM'] = gpm_df2.groupby('SYMBOL', group_keys=False).apply(lambda x: x['GROSS_PROFIT'].div(x['NET_SALES']))\n",
    "# gpm_df2['GPM'] = gpm_df2['GPM']*100\n",
    "# #   GPM rowth Calculation\n",
    "# def calculate_yoy_GPM_growth(GPM):\n",
    "#     \"\"\"Calculates YoY EPS Growth based on the provided rules.\"\"\"\n",
    "#     growth = []\n",
    "#     for i in range(len(GPM)):\n",
    "#         if i < 4:\n",
    "#             growth.append(np.nan) \n",
    "#         else:\n",
    "#             prev_eps = GPM.iloc[i - 4]  \n",
    "#             curr_eps = GPM.iloc[i]      \n",
    "#             if prev_eps > 0:\n",
    "#                 growth.append((curr_eps - prev_eps) / prev_eps)\n",
    "#             elif prev_eps < 0:\n",
    "#                 growth.append(-(curr_eps - prev_eps) / prev_eps)\n",
    "#             else:\n",
    "#                 growth.append(np.nan)  \n",
    "#     return pd.Series(growth, index=GPM.index)  \n",
    "\n",
    "# # Calculating YoY EPS Growth for each quarter\n",
    "# gpm_df2['YoY_GPM'] = gpm_df2.groupby('SYMBOL')['GPM'].transform(calculate_yoy_GPM_growth)\n",
    "\n",
    "# #   NIM rowth Calculation\n",
    "# def calculate_yoy_NIM_growth(NIM):\n",
    "#     \"\"\"Calculates YoY EPS Growth based on the provided rules.\"\"\"\n",
    "#     growth = []\n",
    "#     for i in range(len(NIM)):\n",
    "#         if i < 4:\n",
    "#             growth.append(np.nan) \n",
    "#         else:\n",
    "#             prev_eps = NIM.iloc[i - 4]  \n",
    "#             curr_eps = NIM.iloc[i]      \n",
    "#             if prev_eps > 0:\n",
    "#                 growth.append((curr_eps - prev_eps) / prev_eps)\n",
    "#             elif prev_eps < 0:\n",
    "#                 growth.append(-(curr_eps - prev_eps) / prev_eps)\n",
    "#             else:\n",
    "#                 growth.append(np.nan)  \n",
    "#     return pd.Series(growth, index=NIM.index)  \n",
    "\n",
    "# # Calculating YoY EPS Growth for each quarter\n",
    "# gpm_df2['YoY_NIM'] = gpm_df2.groupby('SYMBOL')['NIM'].transform(calculate_yoy_NIM_growth)\n",
    "# gpm_df2 = gpm_df2[['Date_End', 'Fincode', 'YoY_GPM','YoY_NIM']]\n",
    "# gpm_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = X[['Fincode','Date_End','Debt/Equity Ratio', 'Adj_eps_abs']]\n",
    "quality = pd.merge(quality, roe_ttm, on=['Fincode', 'Date_End'])\n",
    "pl_quality = pd.merge(quality, company_master, how='inner', left_on='Fincode', right_on='FINCODE')\n",
    "# pl_quality2 = pd.merge(pl_quality, opm_df3, on=['Fincode', 'Date_End'], how='inner')\n",
    "# # print(pl_quality2.columns)\n",
    "# pl_quality3 = pd.merge(pl_quality2, gpm_df2, on=['Fincode', 'Date_End'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pl_quality[['Fincode', 'Date_End', 'Debt/Equity Ratio', 'ROE_ttm', 'SYMBOL', 'Adj_eps_abs']].reset_index(drop=True)\n",
    "\n",
    "# Removing the rows with NaN Symbol Names\n",
    "a = a[a.SYMBOL.notna()]\n",
    "\n",
    "# Filtering Stocks which have been historically in top 500 universe only.\n",
    "b = a[a.SYMBOL.isin(top_500.Symbol.unique())]\n",
    "\n",
    "# Filter out stocks with fewer than 4 quarters of history\n",
    "symbol_quarter_counts = b.groupby('SYMBOL').size()\n",
    "valid_symbols = symbol_quarter_counts[symbol_quarter_counts >= 4].index\n",
    "b = b[b['SYMBOL'].isin(valid_symbols)]\n",
    "\n",
    "# Define a function to check for 2 consecutive quarters of negative EPS within a 1-year period\n",
    "def has_2_consecutive_negative_in_last_1_year(series):\n",
    "    return series.rolling(window=4, min_periods=4).apply(\n",
    "        lambda x: any((x[i] < 0 and x[i + 1] < 0) for i in range(len(x) - 1)), raw=True\n",
    "    )\n",
    "\n",
    "# Apply the function to create a flag for exclusion\n",
    "b['exclude_flag'] = b.groupby('SYMBOL')['Adj_eps_abs'].transform(has_2_consecutive_negative_in_last_1_year)\n",
    "\n",
    "# Filter out rows based on the exclude flag\n",
    "b_filtered = b[b['exclude_flag'] != 1].reset_index(drop=True)\n",
    "\n",
    "# Drop the intermediate column used for filtering\n",
    "b_filtered = b_filtered.drop(columns=['exclude_flag'])\n",
    "\n",
    "# Calculate Adjusted EPS TTM\n",
    "b_filtered['Adj_eps_abs_TTM'] = b_filtered.groupby('SYMBOL')['Adj_eps_abs'].transform(lambda x: x.rolling(4).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pl_quality[['Fincode', 'Date_End', 'Debt/Equity Ratio', 'ROE_ttm', 'SYMBOL', 'Adj_eps_abs']].reset_index(drop=True)\n",
    "\n",
    "# # Removing the rows with NaN Symbol Names\n",
    "# a = a[a.SYMBOL.notna()]\n",
    "\n",
    "# # Filtering Stocks which have been historically in top 500 universe only.\n",
    "# b = a[a.SYMBOL.isin(top_500.Symbol.unique())]\n",
    "\n",
    "# # Calculate Adjusted EPS TTM\n",
    "# b['Adj_eps_abs_TTM'] = b.groupby('SYMBOL')['Adj_eps_abs'].transform(lambda x: x.rolling(4).sum())\n",
    "\n",
    "# # Define a function to check for negatives in the last 16 quarters\n",
    "# def has_negative_in_last_4_years(series):\n",
    "#     return series.rolling(window=16, min_periods=16).apply(lambda x: (x < 0).any(), raw=True)\n",
    "\n",
    "# # Apply the function to create a flag for exclusion\n",
    "# b['exclude_flag'] = b.groupby('SYMBOL')['Adj_eps_abs_TTM'].transform(has_negative_in_last_4_years)\n",
    "\n",
    "# # Remove symbols with fewer than 16 quarters of data\n",
    "# # Count the number of quarters for each symbol\n",
    "# symbol_quarter_counts = b.groupby('SYMBOL').size()\n",
    "\n",
    "# # Create a list of symbols with at least 16 quarters\n",
    "# valid_symbols = symbol_quarter_counts[symbol_quarter_counts >= 16].index\n",
    "\n",
    "# # Filter the DataFrame to keep only rows with valid symbols\n",
    "# b = b[b['SYMBOL'].isin(valid_symbols)]\n",
    "\n",
    "# # Filter out rows based on the exclude flag\n",
    "# b_filtered = b[b['exclude_flag'] != 1].reset_index(drop=True)\n",
    "\n",
    "# # Drop the intermediate column used for filtering\n",
    "# b_filtered = b_filtered.drop(columns=['exclude_flag'])\n",
    "\n",
    "# Mapping GICS to each Symbol\n",
    "# SectorThemeGICS = d.fetch_data_from_database(table_name='SectorThemeGICS', no_of_years=25)\n",
    "\n",
    "SectorThemeGICS = pd.read_excel('SectorMapping.xlsx')\n",
    "df = pd.merge(b_filtered, SectorThemeGICS[['Symbol', 'Sector']], left_on='SYMBOL', right_on='Symbol', how='left')\n",
    "\n",
    "# Calculating ROE for TTM for the past 3 Years years\n",
    "df['ROE_ttm'] = df.groupby('Symbol')['ROE_ttm'].transform(lambda x : x.rolling(12).mean())\n",
    "\n",
    "# Create a new column for quarter information\n",
    "df['Quarter'] = pd.to_datetime(df['Date_End'], format='%Y%m').dt.quarter\n",
    "\n",
    "#  EPS Growth Calculation\n",
    "def calculate_yoy_eps_growth(eps):\n",
    "    \"\"\"Calculates YoY EPS Growth based on the provided rules.\"\"\"\n",
    "    growth = []\n",
    "    for i in range(len(eps)):\n",
    "        if i < 4:\n",
    "            growth.append(np.nan) \n",
    "        else:\n",
    "            prev_eps = eps.iloc[i - 4]  \n",
    "            curr_eps = eps.iloc[i]      \n",
    "            if prev_eps > 0:\n",
    "                growth.append((curr_eps - prev_eps) / prev_eps)\n",
    "            elif prev_eps < 0:\n",
    "                growth.append(-(curr_eps - prev_eps) / prev_eps)\n",
    "            else:\n",
    "                growth.append(np.nan)  \n",
    "    return pd.Series(growth, index=eps.index)  \n",
    "\n",
    "# Calculating YoY EPS Growth for each quarter\n",
    "df['YoY_EPS_Growth'] = df.groupby('SYMBOL')['Adj_eps_abs'].transform(calculate_yoy_eps_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 3-year mean and std deviation for each quarter separately\n",
    "def calc_quarterly_stats(group):\n",
    "    group = group.sort_values('Date_End')\n",
    "    group['Mean_YoY_EPS_Growth'] = group['YoY_EPS_Growth'].rolling(window=3, min_periods=1).mean()\n",
    "    group['Std_YoY_EPS_Growth'] = group['YoY_EPS_Growth'].rolling(window=3, min_periods=1).std()\n",
    "    return group\n",
    "\n",
    "# Apply function to each SYMBOL and Quarter group\n",
    "df = df.groupby(['SYMBOL', 'Quarter'], group_keys=False).apply(calc_quarterly_stats)\n",
    "\n",
    "# Dropping Quarter column after calculation to keep the original dataframe structure\n",
    "df.drop(columns=['Quarter'], inplace=True)\n",
    "\n",
    "# Calculating rolling 3-year mean and std deviation for EPS growth\n",
    "df['Mean_YoY_EPS_Growth'] = df.groupby('SYMBOL')['YoY_EPS_Growth'].transform(lambda x: x.rolling(window=12,min_periods=4).mean())\n",
    "df['Std_YoY_EPS_Growth'] = df.groupby('SYMBOL')['YoY_EPS_Growth'].transform(lambda x: x.rolling(window=12,min_periods=4).std())\n",
    "\n",
    "# Calulating EPS Growth Variability\n",
    "df['EPS_Growth_Variability'] = df['Mean_YoY_EPS_Growth'].div(df['Std_YoY_EPS_Growth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate 5-year mean and std deviation for each quarter separately\n",
    "# def calc_quarterly_stats(group):\n",
    "#     group = group.sort_values('Date_End')\n",
    "#     group['Mean_YoY_GPM_Growth'] = group['YoY_GPM'].rolling(window=5, min_periods=1).mean()\n",
    "#     group['Std_YoY_GPM_Growth'] = group['YoY_GPM'].rolling(window=5, min_periods=1).std()\n",
    "#     return group\n",
    "\n",
    "# # Apply function to each SYMBOL and Quarter group\n",
    "# df = df.groupby(['SYMBOL', 'Quarter'], group_keys=False).apply(calc_quarterly_stats)\n",
    "# # Dropping Quarter column after calculation to keep the original dataframe structure\n",
    "# # df.drop(columns=['Quarter'], inplace=True)\n",
    "\n",
    "# # Calculating rolling 5-year mean and std deviation for EPS growth\n",
    "# df['Mean_YoY_GPM_Growth'] = df.groupby('SYMBOL')['YoY_GPM'].transform(lambda x: x.rolling(window=20).mean())\n",
    "# df['Std_YoY_GPM_Growth'] = df.groupby('SYMBOL')['YoY_GPM'].transform(lambda x: x.rolling(window=20).std())\n",
    "\n",
    "# # Calulating EPS Growth Variability\n",
    "# df['GPM_Growth_Variability'] = df['Mean_YoY_GPM_Growth'].div(df['Std_YoY_GPM_Growth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate 5-year mean and std deviation for each quarter separately\n",
    "# def calc_quarterly_stats(group):\n",
    "#     group = group.sort_values('Date_End')\n",
    "#     group['Mean_YoY_NIM_Growth'] = group['YoY_NIM'].rolling(window=5, min_periods=1).mean()\n",
    "#     group['Std_YoY_NIM_Growth'] = group['YoY_NIM'].rolling(window=5, min_periods=1).std()\n",
    "#     return group\n",
    "\n",
    "# # Apply function to each SYMBOL and Quarter group\n",
    "# df = df.groupby(['SYMBOL', 'Quarter'], group_keys=False).apply(calc_quarterly_stats)\n",
    "# # Dropping Quarter column after calculation to keep the original dataframe structure\n",
    "# df.drop(columns=['Quarter'], inplace=True)\n",
    "\n",
    "# # Calculating rolling 5-year mean and std deviation for EPS growth\n",
    "# df['Mean_YoY_NIM_Growth'] = df.groupby('SYMBOL')['YoY_NIM'].transform(lambda x: x.rolling(window=20).mean())\n",
    "# df['Std_YoY_NIM_Growth'] = df.groupby('SYMBOL')['YoY_NIM'].transform(lambda x: x.rolling(window=20).std())\n",
    "\n",
    "# # Calulating EPS Growth Variability\n",
    "# df['NIM_Growth_Variability'] = df['Mean_YoY_NIM_Growth'].div(df['Std_YoY_NIM_Growth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into three sectors: Bank, Finance, and Others\n",
    "bank_df = df[df['Sector'] == 'Bank']\n",
    "finance_df = df[df['Sector'] == 'Finance']\n",
    "non_financials_df = df[~df['Sector'].isin(['Bank', 'Finance'])]\n",
    "\n",
    "# Calculate metrics for Bank sector\n",
    "bank_df['mean_roe_bank'] = bank_df.groupby('Date_End')['ROE_ttm'].transform('mean')\n",
    "bank_df['std_roe_bank'] = bank_df.groupby('Date_End')['ROE_ttm'].transform('std')\n",
    "bank_df['mean_eps_growth_variability_bank'] = bank_df.groupby('Date_End')['EPS_Growth_Variability'].transform('mean')\n",
    "bank_df['std_eps_growth_variability_bank'] = bank_df.groupby('Date_End')['EPS_Growth_Variability'].transform('std')\n",
    "\n",
    "# Calculate metrics for Finance sector\n",
    "finance_df['mean_roe_fin'] = finance_df.groupby('Date_End')['ROE_ttm'].transform('mean')\n",
    "finance_df['std_roe_fin'] = finance_df.groupby('Date_End')['ROE_ttm'].transform('std')\n",
    "finance_df['mean_eps_growth_variability_fin'] = finance_df.groupby('Date_End')['EPS_Growth_Variability'].transform('mean')\n",
    "finance_df['std_eps_growth_variability_fin'] = finance_df.groupby('Date_End')['EPS_Growth_Variability'].transform('std')\n",
    "\n",
    "# Calculate metrics for non-financials\n",
    "non_financials_df['mean_roe'] = non_financials_df.groupby('Date_End')['ROE_ttm'].transform('mean')\n",
    "non_financials_df['std_roe'] = non_financials_df.groupby('Date_End')['ROE_ttm'].transform('std')\n",
    "non_financials_df['mean_de'] = non_financials_df.groupby('Date_End')['Debt/Equity Ratio'].transform('mean')\n",
    "non_financials_df['std_de'] = non_financials_df.groupby('Date_End')['Debt/Equity Ratio'].transform('std')\n",
    "non_financials_df['mean_eps_growth_variability'] = non_financials_df.groupby('Date_End')['EPS_Growth_Variability'].transform('mean')\n",
    "non_financials_df['std_eps_growth_variability'] = non_financials_df.groupby('Date_End')['EPS_Growth_Variability'].transform('std')\n",
    "\n",
    "# Z-Score calculations for Bank sector\n",
    "bank_df['Z_ROE_ttm_bank'] = (bank_df['ROE_ttm'] - bank_df['mean_roe_bank']) / bank_df['std_roe_bank']\n",
    "bank_df['Z_EPS_Growth_Variability_bank'] = (bank_df['EPS_Growth_Variability'] - bank_df['mean_eps_growth_variability_bank']) / bank_df['std_eps_growth_variability_bank']\n",
    "\n",
    "# Z-Score calculations for Finance sector\n",
    "finance_df['Z_ROE_ttm_fin'] = (finance_df['ROE_ttm'] - finance_df['mean_roe_fin']) / finance_df['std_roe_fin']\n",
    "finance_df['Z_EPS_Growth_Variability_fin'] = (finance_df['EPS_Growth_Variability'] - finance_df['mean_eps_growth_variability_fin']) / finance_df['std_eps_growth_variability_fin']\n",
    "\n",
    "# Z-Score calculations for non-financials\n",
    "non_financials_df['Z_ROE_ttm'] = (non_financials_df['ROE_ttm'] - non_financials_df['mean_roe']) / non_financials_df['std_roe']\n",
    "non_financials_df['Z_DE'] = (non_financials_df['Debt/Equity Ratio'] - non_financials_df['mean_de']) / non_financials_df['std_de']\n",
    "non_financials_df['Z_EPS_Growth_Variability'] = (non_financials_df['EPS_Growth_Variability'] - non_financials_df['mean_eps_growth_variability']) / non_financials_df['std_eps_growth_variability']\n",
    "\n",
    "# Weighted Average Z Quality Score calculation\n",
    "def calculate_weighted_avg_z(row):\n",
    "    if row['Sector'] == 'Bank':\n",
    "        return (1/2) * row['Z_ROE_ttm_bank'] - (1/2) * abs(row['Z_EPS_Growth_Variability_bank'])\n",
    "    elif row['Sector'] == 'Finance':\n",
    "        return (1/2) * row['Z_ROE_ttm_fin'] - (1/2) * abs(row['Z_EPS_Growth_Variability_fin'])\n",
    "    else:\n",
    "        return (1/3) * row['Z_ROE_ttm'] - (1/3) * abs(row['Z_DE']) - (1/3) * abs(row['Z_EPS_Growth_Variability'])\n",
    "\n",
    "# Combine all dataframes\n",
    "df_combined = pd.concat([bank_df, finance_df, non_financials_df]).reset_index(drop=True)\n",
    "\n",
    "# Calculate weighted average Z-score\n",
    "df_combined['WeightedAvgZ'] = df_combined.apply(calculate_weighted_avg_z, axis=1)\n",
    "\n",
    "# Calculate Normalized Quality Score\n",
    "df_combined['Quality_Score'] = np.where(df_combined['WeightedAvgZ'] >= 0, \n",
    "                                      1 + df_combined['WeightedAvgZ'], \n",
    "                                      (1 - df_combined['WeightedAvgZ'])**-1)\n",
    "\n",
    "# Final dataframe with required columns\n",
    "df = df_combined[['Date_End', 'Symbol', 'Sector', 'Quality_Score']].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GrowthDate = d.fetch_data_from_database(table_name='GrowthDate', no_of_years=25)[['Date', 'Qtr']]\n",
    "# GrowthDate['Qtr'] = GrowthDate['Qtr'].astype('int')\n",
    "# final_df =  pd.merge(df, GrowthDate, left_on='Date_End', right_on='Qtr').drop(columns=['Date_End', 'Qtr'])\n",
    "# final_df = final_df[['Date', 'Symbol', 'Sector', 'Quality_Score']].sort_values(by='Date').reset_index(drop=True)\n",
    "# price_data['Date'] = pd.to_datetime(price_data['Date'])\n",
    "# price_data.drop(columns='Unnamed: 0', inplace=True)\n",
    "# merged_df = pd.merge(final_df[['Date', 'Symbol', 'Quality_Score']], price_data, on=['Date', 'Symbol'], how='outer')\n",
    "# merged_df['Quality_Score'] = merged_df.groupby('Symbol', group_keys=False)['Quality_Score'].apply(lambda x: x.fillna(method='ffill'))\n",
    "# merged_df\n",
    "# merged_df.tail(500).dropna().sort_values(by='Quality_pct_rank', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['Quality_pct_rank'] = df.groupby('Date_End', group_keys=False)['Quality_Score'].apply(lambda x : x.rank(pct=True))\n",
    "# GrowthDate = d.fetch_data_from_database(table_name='GrowthDate', no_of_years=25)[['Date', 'Qtr']]\n",
    "GrowthDate = pd.read_csv('GrowthDate.csv')[['Date', 'Qtr']]\n",
    "GrowthDate['Qtr'] = GrowthDate['Qtr'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Quality_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>BANKINDIA</td>\n",
       "      <td>Bank</td>\n",
       "      <td>0.703128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>J&amp;KBANK</td>\n",
       "      <td>Bank</td>\n",
       "      <td>0.688327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>BAJAJHLDNG</td>\n",
       "      <td>Finance</td>\n",
       "      <td>0.740377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>IDBI</td>\n",
       "      <td>Bank</td>\n",
       "      <td>0.652245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>PNB</td>\n",
       "      <td>Bank</td>\n",
       "      <td>0.866487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47526</th>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>BRIGADE</td>\n",
       "      <td>Realty</td>\n",
       "      <td>0.805791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47527</th>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>KOKUYOCMLN</td>\n",
       "      <td>FMCG</td>\n",
       "      <td>0.518851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47528</th>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>SECURKLOUD</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.757954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47529</th>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>TATACHEM</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>0.813175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47530</th>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>PALREDTEC</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.510923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47531 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Symbol     Sector  Quality_Score\n",
       "0      2006-05-31   BANKINDIA       Bank       0.703128\n",
       "1      2006-05-31     J&KBANK       Bank       0.688327\n",
       "2      2006-05-31  BAJAJHLDNG    Finance       0.740377\n",
       "3      2006-05-31        IDBI       Bank       0.652245\n",
       "4      2006-05-31         PNB       Bank       0.866487\n",
       "...           ...         ...        ...            ...\n",
       "47526  2024-11-18     BRIGADE     Realty       0.805791\n",
       "47527  2024-11-18  KOKUYOCMLN       FMCG       0.518851\n",
       "47528  2024-11-18  SECURKLOUD         IT       0.757954\n",
       "47529  2024-11-18    TATACHEM  Chemicals       0.813175\n",
       "47530  2024-11-18   PALREDTEC         IT       0.510923\n",
       "\n",
       "[47531 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GrowthDate Mapping  \n",
    "final_df =  pd.merge(df, GrowthDate, left_on='Date_End', right_on='Qtr').drop(columns=['Date_End', 'Qtr'])\n",
    "final_df = final_df[['Date', 'Symbol', 'Sector', 'Quality_Score']].sort_values(by='Date').reset_index(drop=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Quality Ranks with price data universe\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date'])\n",
    "final_df['Date'] = pd.to_datetime(final_df['Date'])\n",
    "merged_df = pd.merge(final_df[['Date', 'Symbol', 'Quality_Score']], price_data, on=['Date', 'Symbol'], how='outer')\n",
    "merged_df =  merged_df.groupby('Date', group_keys= False).apply(lambda x: x.sort_values(by='Mcap', ascending=False).head(500))\n",
    "merged_df['Quality_pct_rank'] = merged_df.groupby('Date', group_keys=False)['Quality_Score'].apply(lambda x : x.rank(pct=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Quality_Score</th>\n",
       "      <th>Quality_pct_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1995-05-02</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1995-05-02</td>\n",
       "      <td>TATASTEEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1995-05-02</td>\n",
       "      <td>HINDPETRO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-05-02</td>\n",
       "      <td>GRASIM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-05-02</td>\n",
       "      <td>BPCL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7479537</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>ARVIND</td>\n",
       "      <td>1.011440</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480988</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>RAILTEL</td>\n",
       "      <td>0.523958</td>\n",
       "      <td>0.086294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480611</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>MARKSANS</td>\n",
       "      <td>0.721118</td>\n",
       "      <td>0.403553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480807</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>OLECTRA</td>\n",
       "      <td>0.697492</td>\n",
       "      <td>0.337563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480956</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>PRUDENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2949507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date     Symbol  Quality_Score  Quality_pct_rank\n",
       "7       1995-05-02   RELIANCE            NaN               NaN\n",
       "9       1995-05-02  TATASTEEL            NaN               NaN\n",
       "5       1995-05-02  HINDPETRO            NaN               NaN\n",
       "3       1995-05-02     GRASIM            NaN               NaN\n",
       "1       1995-05-02       BPCL            NaN               NaN\n",
       "...            ...        ...            ...               ...\n",
       "7479537 2025-04-28     ARVIND       1.011440          0.685714\n",
       "7480988 2025-04-28    RAILTEL       0.523958          0.086294\n",
       "7480611 2025-04-28   MARKSANS       0.721118          0.403553\n",
       "7480807 2025-04-28    OLECTRA       0.697492          0.337563\n",
       "7480956 2025-04-28    PRUDENT            NaN               NaN\n",
       "\n",
       "[2949507 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[['Quality_pct_rank', 'Quality_Score']] = merged_df.groupby('Symbol', group_keys=False)[['Quality_pct_rank', 'Quality_Score']].apply(lambda x: x.fillna(method='ffill'))\n",
    "qualityfinal = merged_df[['Date','Symbol','Quality_Score','Quality_pct_rank']]\n",
    "qualityfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top500 = qualityfinal.filter([\"Symbol\", \"Date\",\"Quality_Score\"])\n",
    "\n",
    "## Convert the long from Dataframe to wide form dataframe\n",
    "top500 = top500.pivot_table(index='Date',columns='Symbol',values='Quality_Score').reset_index()\n",
    "## Shifting the Date column\n",
    "top500[\"Date\"] = top500[\"Date\"].shift(-1)\n",
    "## Fill NaN value of date with todays date.\n",
    "top500.iloc[-1, top500.columns.get_loc(\"Date\")] = pd.to_datetime(date.today())\n",
    "\n",
    "## Re-converting the wide form dataframe to long form dataframe\n",
    "top500 = top500.melt(id_vars='Date', value_name = \"Quality_Score\")\n",
    "## Drop na and reset the index\n",
    "top500 = top500.dropna().reset_index(drop = True)\n",
    "top500 = top500[top500[\"Date\"] >= \"2006-01-01\"].reset_index(drop = True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['Quality_Score'] = merged_df.groupby('Symbol', group_keys=False)['Quality_Score'].apply(lambda x: x.fillna(method='ffill'))\n",
    "# merged_df.dropna(inplace=True)\n",
    "# merged_df = merged_df[['Date','Symbol','Quality_Score']]\n",
    "# merged_df.to_csv('Akshat_Quality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not dropped NaNs\n",
    "top500.to_csv('iii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Quality_Score</th>\n",
       "      <th>Quality_pct_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-10-20</td>\n",
       "      <td>IDBI</td>\n",
       "      <td>0.805616</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-10-20</td>\n",
       "      <td>J&amp;KBANK</td>\n",
       "      <td>0.804224</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-10-20</td>\n",
       "      <td>INGVYSYABK</td>\n",
       "      <td>0.789333</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-10-20</td>\n",
       "      <td>ORIENTBANK</td>\n",
       "      <td>0.788121</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-10-20</td>\n",
       "      <td>AXISBANK</td>\n",
       "      <td>0.782608</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>GODREJIND</td>\n",
       "      <td>0.293667</td>\n",
       "      <td>0.007772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>JSWSTEEL</td>\n",
       "      <td>0.279599</td>\n",
       "      <td>0.010152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>FLUOROCHEM</td>\n",
       "      <td>0.272366</td>\n",
       "      <td>0.007614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>RAMCOCEM</td>\n",
       "      <td>0.260914</td>\n",
       "      <td>0.005076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>ERIS</td>\n",
       "      <td>0.235635</td>\n",
       "      <td>0.002538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2450 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Symbol  Quality_Score  Quality_pct_rank\n",
       "0    2008-10-20        IDBI       0.805616          0.694444\n",
       "1    2008-10-20     J&KBANK       0.804224          0.666667\n",
       "2    2008-10-20  INGVYSYABK       0.789333          0.638889\n",
       "3    2008-10-20  ORIENTBANK       0.788121          0.611111\n",
       "4    2008-10-20    AXISBANK       0.782608          0.583333\n",
       "...         ...         ...            ...               ...\n",
       "2445 2024-12-18   GODREJIND       0.293667          0.007772\n",
       "2446 2024-12-18    JSWSTEEL       0.279599          0.010152\n",
       "2447 2024-12-18  FLUOROCHEM       0.272366          0.007614\n",
       "2448 2024-12-18    RAMCOCEM       0.260914          0.005076\n",
       "2449 2024-12-18        ERIS       0.235635          0.002538\n",
       "\n",
       "[2450 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebalanceFrequency=2\n",
    "# from rebalancedate import *\n",
    "# op=rebalancedates(price_data,'2006-06-02',17, rebalanceFrequency)\n",
    "# rebalanceDates=op\n",
    "# df_rebalance_dates = pd.DataFrame({'Timestamp': pd.to_datetime(rebalanceDates)})\n",
    "# df_rebalance_dates.rename(columns={'Timestamp': 'Date'}, inplace=True)\n",
    "# qualityfinal['Date'] = pd.to_datetime(qualityfinal['Date'])\n",
    "# qualityfinal = qualityfinal[qualityfinal['Date'].isin(df_rebalance_dates['Date'])].reset_index(drop=True)\n",
    "# top_stocks = 25\n",
    "# df_stocks = qualityfinal.copy()\n",
    "# df_stocks = df_stocks.groupby('Date').apply(lambda x: x.nlargest(top_stocks, 'Quality_Score')).reset_index(drop=True)\n",
    "# df_stocks\n",
    "qualf = qualityfinal.dropna()\n",
    "qualf = qualf.sort_values(by=['Date','Quality_Score'], ascending=[True,False])\n",
    "top_25_stocks_each_day = qualf.groupby('Date').tail(25)\n",
    "top_25_stocks_each_day['Date'] = pd.to_datetime(top_25_stocks_each_day['Date'])\n",
    "rebalanceFrequency=2\n",
    "from rebalancedate import *\n",
    "op=rebalancedates(price_data,'2006-06-02',17, rebalanceFrequency)\n",
    "rebalanceDates=op[1]\n",
    "df_rebalance_dates = pd.DataFrame({'Date': pd.to_datetime(rebalanceDates)})\n",
    "df_rebalance_dates\n",
    "top_25_stocks_each_day = top_25_stocks_each_day[top_25_stocks_each_day['Date'].isin(df_rebalance_dates['Date'])].reset_index(drop=True)\n",
    "top_25_stocks_each_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_25_stocks_each_day.to_csv('QualityShort.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Quality_Score</th>\n",
       "      <th>Quality_pct_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2621187</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>HDFCAMC</td>\n",
       "      <td>2.286558</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369533</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>COALINDIA</td>\n",
       "      <td>2.190064</td>\n",
       "      <td>0.997462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413235</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>NAM-INDIA</td>\n",
       "      <td>2.100873</td>\n",
       "      <td>0.994924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714654</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>SBICARD</td>\n",
       "      <td>1.936810</td>\n",
       "      <td>0.992386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5356595</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>RECLTD</td>\n",
       "      <td>1.901405</td>\n",
       "      <td>0.989848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930449</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>PFC</td>\n",
       "      <td>1.754050</td>\n",
       "      <td>0.987310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750442</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>BAJFINANCE</td>\n",
       "      <td>1.729338</td>\n",
       "      <td>0.984772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54989</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>360ONE</td>\n",
       "      <td>1.700138</td>\n",
       "      <td>0.982234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277076</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>CGPOWER</td>\n",
       "      <td>1.670161</td>\n",
       "      <td>0.979695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452768</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>CREDITACC</td>\n",
       "      <td>1.655558</td>\n",
       "      <td>0.977157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763747</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>HINDZINC</td>\n",
       "      <td>1.648968</td>\n",
       "      <td>0.974619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732425</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>BAJAJFINSV</td>\n",
       "      <td>1.602614</td>\n",
       "      <td>0.972081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792048</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>TVSHLTD</td>\n",
       "      <td>1.590258</td>\n",
       "      <td>0.969543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431229</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>GRAVITA</td>\n",
       "      <td>1.565321</td>\n",
       "      <td>0.967005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970679</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>MAHABANK</td>\n",
       "      <td>1.560649</td>\n",
       "      <td>0.964467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6918507</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>UTIAMC</td>\n",
       "      <td>1.529546</td>\n",
       "      <td>0.961929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868318</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>ICICIBANK</td>\n",
       "      <td>1.517131</td>\n",
       "      <td>0.959391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075616</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>BPCL</td>\n",
       "      <td>1.512566</td>\n",
       "      <td>0.956853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360963</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>REDINGTON</td>\n",
       "      <td>1.490719</td>\n",
       "      <td>0.954315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908262</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>SHRIRAMFIN</td>\n",
       "      <td>1.487836</td>\n",
       "      <td>0.951777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6259838</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>SUNDARMFIN</td>\n",
       "      <td>1.485501</td>\n",
       "      <td>0.949239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6535741</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>TCS</td>\n",
       "      <td>1.420353</td>\n",
       "      <td>0.946701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197923</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>CASTROLIND</td>\n",
       "      <td>1.361572</td>\n",
       "      <td>0.944162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723006</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>SBIN</td>\n",
       "      <td>1.354899</td>\n",
       "      <td>0.941624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629562</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>ATGL</td>\n",
       "      <td>1.343156</td>\n",
       "      <td>0.939086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602941</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>NMDC</td>\n",
       "      <td>1.307327</td>\n",
       "      <td>0.936548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312132</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>CHOLAFIN</td>\n",
       "      <td>1.305602</td>\n",
       "      <td>0.934010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095769</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>INFY</td>\n",
       "      <td>1.305374</td>\n",
       "      <td>0.931472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843981</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>HUDCO</td>\n",
       "      <td>1.301379</td>\n",
       "      <td>0.928934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042275</th>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>BLUESTARCO</td>\n",
       "      <td>1.300558</td>\n",
       "      <td>0.926396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date      Symbol  Quality_Score  Quality_pct_rank\n",
       "2621187 2025-01-17     HDFCAMC       2.286558          1.000000\n",
       "1369533 2025-01-17   COALINDIA       2.190064          0.997462\n",
       "4413235 2025-01-17   NAM-INDIA       2.100873          0.994924\n",
       "5714654 2025-01-17     SBICARD       1.936810          0.992386\n",
       "5356595 2025-01-17      RECLTD       1.901405          0.989848\n",
       "4930449 2025-01-17         PFC       1.754050          0.987310\n",
       "750442  2025-01-17  BAJFINANCE       1.729338          0.984772\n",
       "54989   2025-01-17      360ONE       1.700138          0.982234\n",
       "1277076 2025-01-17     CGPOWER       1.670161          0.979695\n",
       "1452768 2025-01-17   CREDITACC       1.655558          0.977157\n",
       "2763747 2025-01-17    HINDZINC       1.648968          0.974619\n",
       "732425  2025-01-17  BAJAJFINSV       1.602614          0.972081\n",
       "6792048 2025-01-17     TVSHLTD       1.590258          0.969543\n",
       "2431229 2025-01-17     GRAVITA       1.565321          0.967005\n",
       "3970679 2025-01-17    MAHABANK       1.560649          0.964467\n",
       "6918507 2025-01-17      UTIAMC       1.529546          0.961929\n",
       "2868318 2025-01-17   ICICIBANK       1.517131          0.959391\n",
       "1075616 2025-01-17        BPCL       1.512566          0.956853\n",
       "5360963 2025-01-17   REDINGTON       1.490719          0.954315\n",
       "5908262 2025-01-17  SHRIRAMFIN       1.487836          0.951777\n",
       "6259838 2025-01-17  SUNDARMFIN       1.485501          0.949239\n",
       "6535741 2025-01-17         TCS       1.420353          0.946701\n",
       "1197923 2025-01-17  CASTROLIND       1.361572          0.944162\n",
       "5723006 2025-01-17        SBIN       1.354899          0.941624\n",
       "629562  2025-01-17        ATGL       1.343156          0.939086\n",
       "4602941 2025-01-17        NMDC       1.307327          0.936548\n",
       "1312132 2025-01-17    CHOLAFIN       1.305602          0.934010\n",
       "3095769 2025-01-17        INFY       1.305374          0.931472\n",
       "2843981 2025-01-17       HUDCO       1.301379          0.928934\n",
       "1042275 2025-01-17  BLUESTARCO       1.300558          0.926396"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualityfinal[qualityfinal['Date'] == '2025-01-17'].sort_values(by='Quality_Score', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the specific date\n",
    "data_all = qualityfinal[qualityfinal['Date'] == '2024-12-06']\n",
    "\n",
    "# Filter after dropping NaN values\n",
    "data_no_na = qualityfinal[qualityfinal['Date'] == '2024-12-06'].dropna()\n",
    "\n",
    "# Companies present before dropping NaNs\n",
    "companies_with_na = data_all['Symbol']\n",
    "\n",
    "# Companies remaining after dropping NaNs\n",
    "companies_without_na = data_no_na['Symbol']\n",
    "\n",
    "# Identify companies dropped due to NaNs\n",
    "dropped_due_to_na = companies_with_na[~companies_with_na.isin(companies_without_na)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       With_NaN Without_NaN Dropped_Due_To_NaN\n",
      "0      RELIANCE    RELIANCE               LICI\n",
      "1           TCS         TCS             ZOMATO\n",
      "2      HDFCBANK    HDFCBANK             JIOFIN\n",
      "3    BHARTIARTL  BHARTIARTL         ADANIGREEN\n",
      "4     ICICIBANK   ICICIBANK            HYUNDAI\n",
      "..          ...         ...                ...\n",
      "495    SAPPHIRE        None               None\n",
      "496    INDIACEM        None               None\n",
      "497         SCI        None               None\n",
      "498     KIRLPNU        None               None\n",
      "499  SANOFICONR        None               None\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter for the specific date\n",
    "data_all = qualityfinal[qualityfinal['Date'] == '2024-12-06']\n",
    "\n",
    "# Filter after dropping NaN values\n",
    "data_no_na = qualityfinal[qualityfinal['Date'] == '2024-12-06'].dropna()\n",
    "\n",
    "# Companies present before dropping NaNs\n",
    "companies_with_na = data_all['Symbol']\n",
    "\n",
    "# Companies remaining after dropping NaNs\n",
    "companies_without_na = data_no_na['Symbol']\n",
    "\n",
    "# Identify companies dropped due to NaNs\n",
    "dropped_due_to_na = companies_with_na[~companies_with_na.isin(companies_without_na)]\n",
    "\n",
    "# Save results into a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'With_NaN': companies_with_na.tolist(),\n",
    "    'Without_NaN': companies_without_na.tolist() + [None] * (len(companies_with_na) - len(companies_without_na)),\n",
    "    'Dropped_Due_To_NaN': dropped_due_to_na.tolist() + [None] * (len(companies_with_na) - len(dropped_due_to_na))\n",
    "})\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save to a CSV file\n",
    "results_df.to_csv('dropped_companies_due_to_na.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3222222222222222"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnDf = df_stocks.groupby(\"Date\")[\"Symbol\"].apply(set).rename(\"Current\").reset_index()\n",
    "churnDf[\"Previous\"] = churnDf[\"Current\"].shift()\n",
    "churnDf = churnDf.dropna()\n",
    "churnDf[\"Churn\"] = churnDf.apply(lambda x : len(x[\"Current\"] - x[\"Previous\"])/len(x[\"Previous\"]), axis = 1)\n",
    "churnDf[\"Churn\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks.to_csv('Quality2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   IT\n",
       "1          Diversified\n",
       "2              Finance\n",
       "3                   IT\n",
       "4       Infrastructure\n",
       "             ...      \n",
       "2111    Infrastructure\n",
       "2112         Chemicals\n",
       "2113        Healthcare\n",
       "2114       Hospitality\n",
       "2115                IT\n",
       "Name: Sector, Length: 2116, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
