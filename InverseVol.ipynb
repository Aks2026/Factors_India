{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import os\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pyodbc\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import xlsxwriter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Mcap</th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>3y_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7044</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>360ONE</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1211.50</td>\n",
       "      <td>1113.75</td>\n",
       "      <td>1148.95</td>\n",
       "      <td>408202.0</td>\n",
       "      <td>4.461106e+05</td>\n",
       "      <td>4.690037e+08</td>\n",
       "      <td>2.233405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11884</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>3IINFOLTD</td>\n",
       "      <td>27.85</td>\n",
       "      <td>28.25</td>\n",
       "      <td>26.88</td>\n",
       "      <td>27.43</td>\n",
       "      <td>422842.0</td>\n",
       "      <td>4.650875e+03</td>\n",
       "      <td>1.159856e+07</td>\n",
       "      <td>-0.703299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17575</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>3MINDIA</td>\n",
       "      <td>28960.00</td>\n",
       "      <td>29127.30</td>\n",
       "      <td>28560.15</td>\n",
       "      <td>29020.75</td>\n",
       "      <td>10265.0</td>\n",
       "      <td>3.269208e+05</td>\n",
       "      <td>2.978980e+08</td>\n",
       "      <td>0.163154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29616</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>63MOONS</td>\n",
       "      <td>825.40</td>\n",
       "      <td>825.40</td>\n",
       "      <td>775.55</td>\n",
       "      <td>780.50</td>\n",
       "      <td>306802.0</td>\n",
       "      <td>3.596430e+04</td>\n",
       "      <td>2.394590e+08</td>\n",
       "      <td>2.417999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33091</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>A2ZINFRA</td>\n",
       "      <td>22.10</td>\n",
       "      <td>23.30</td>\n",
       "      <td>21.12</td>\n",
       "      <td>21.35</td>\n",
       "      <td>321282.0</td>\n",
       "      <td>3.760159e+03</td>\n",
       "      <td>6.859371e+06</td>\n",
       "      <td>1.468208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325402</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ZENTEC</td>\n",
       "      <td>2145.00</td>\n",
       "      <td>2148.95</td>\n",
       "      <td>1930.90</td>\n",
       "      <td>1974.20</td>\n",
       "      <td>780773.0</td>\n",
       "      <td>1.782512e+05</td>\n",
       "      <td>1.541402e+09</td>\n",
       "      <td>8.165274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333593</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ZODIACLOTH</td>\n",
       "      <td>122.00</td>\n",
       "      <td>125.05</td>\n",
       "      <td>118.51</td>\n",
       "      <td>121.73</td>\n",
       "      <td>12073.0</td>\n",
       "      <td>3.164215e+03</td>\n",
       "      <td>1.469646e+06</td>\n",
       "      <td>0.137664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7338691</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ZOMATO</td>\n",
       "      <td>207.15</td>\n",
       "      <td>218.20</td>\n",
       "      <td>203.85</td>\n",
       "      <td>216.45</td>\n",
       "      <td>178256196.0</td>\n",
       "      <td>2.088818e+06</td>\n",
       "      <td>3.858355e+10</td>\n",
       "      <td>0.578775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7343668</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ZUARI</td>\n",
       "      <td>210.90</td>\n",
       "      <td>210.90</td>\n",
       "      <td>202.50</td>\n",
       "      <td>207.66</td>\n",
       "      <td>300084.0</td>\n",
       "      <td>8.733766e+03</td>\n",
       "      <td>6.231544e+07</td>\n",
       "      <td>0.773356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353829</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ZYDUSWELL</td>\n",
       "      <td>1858.35</td>\n",
       "      <td>1865.10</td>\n",
       "      <td>1788.25</td>\n",
       "      <td>1803.85</td>\n",
       "      <td>178044.0</td>\n",
       "      <td>1.147828e+05</td>\n",
       "      <td>3.211647e+08</td>\n",
       "      <td>-0.052301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1069 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date      Symbol      Open      High       Low     Close  \\\n",
       "7044     2025-01-22      360ONE   1200.00   1211.50   1113.75   1148.95   \n",
       "11884    2025-01-22   3IINFOLTD     27.85     28.25     26.88     27.43   \n",
       "17575    2025-01-22     3MINDIA  28960.00  29127.30  28560.15  29020.75   \n",
       "29616    2025-01-22     63MOONS    825.40    825.40    775.55    780.50   \n",
       "33091    2025-01-22    A2ZINFRA     22.10     23.30     21.12     21.35   \n",
       "...             ...         ...       ...       ...       ...       ...   \n",
       "7325402  2025-01-22      ZENTEC   2145.00   2148.95   1930.90   1974.20   \n",
       "7333593  2025-01-22  ZODIACLOTH    122.00    125.05    118.51    121.73   \n",
       "7338691  2025-01-22      ZOMATO    207.15    218.20    203.85    216.45   \n",
       "7343668  2025-01-22       ZUARI    210.90    210.90    202.50    207.66   \n",
       "7353829  2025-01-22   ZYDUSWELL   1858.35   1865.10   1788.25   1803.85   \n",
       "\n",
       "              Volume          Mcap     Liquidity  3y_Return  \n",
       "7044        408202.0  4.461106e+05  4.690037e+08   2.233405  \n",
       "11884       422842.0  4.650875e+03  1.159856e+07  -0.703299  \n",
       "17575        10265.0  3.269208e+05  2.978980e+08   0.163154  \n",
       "29616       306802.0  3.596430e+04  2.394590e+08   2.417999  \n",
       "33091       321282.0  3.760159e+03  6.859371e+06   1.468208  \n",
       "...              ...           ...           ...        ...  \n",
       "7325402     780773.0  1.782512e+05  1.541402e+09   8.165274  \n",
       "7333593      12073.0  3.164215e+03  1.469646e+06   0.137664  \n",
       "7338691  178256196.0  2.088818e+06  3.858355e+10   0.578775  \n",
       "7343668     300084.0  8.733766e+03  6.231544e+07   0.773356  \n",
       "7353829     178044.0  1.147828e+05  3.211647e+08  -0.052301  \n",
       "\n",
       "[1069 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# price_data = d.fetch_price_data(no_of_years=20)\n",
    "price_data = pd.read_csv('PriceData_23Jan.csv')\n",
    "df =  price_data.groupby('Date', group_keys= False).apply(lambda x: x.sort_values(by='Mcap', ascending=False).head(500))\n",
    "df = price_data[price_data['Symbol'].isin(df['Symbol'])]\n",
    "df[df['Date'] == '2025-01-22'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate log returns\n",
    "def calculate_log_returns(df):\n",
    "    df['LogReturn'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    return df.dropna()\n",
    "# Apply log return calculation\n",
    "df = df.groupby('Symbol', group_keys=False).apply(calculate_log_returns)\n",
    "\n",
    "# Function to calculate annualized standard deviation\n",
    "def calculate_annualized_std(group, window=252):\n",
    "    return group['LogReturn'].rolling(window).std() * np.sqrt(window)\n",
    "\n",
    "period = 252\n",
    "# Function to calculate annualized downside volatility\n",
    "def calculate_annualized_downside_vol(series, period, annual_trading_days=252):\n",
    "    # Isolate negative returns (only downside)\n",
    "    negative_returns = series.clip(upper=0)\n",
    "    # Calculate rolling downside standard deviation and annualize it\n",
    "    downside_std = negative_returns.rolling(period).std() * np.sqrt(period)\n",
    "    return downside_std\n",
    "\n",
    "# Apply annualized standard deviation calculation within each group\n",
    "df['AnnualizedStd'] = df.groupby('Symbol', group_keys=False).apply(\n",
    "    lambda group: calculate_annualized_std(group)\n",
    ")\n",
    "# # Apply log return calculation\n",
    "# df = df.groupby('Symbol', group_keys=False).apply(calculate_log_returns)\n",
    "# # Calculate annualized downside volatility\n",
    "# df['AnnualizedDownVol'] = df.groupby('Symbol', group_keys=False).apply(\n",
    "#     lambda group: calculate_annualized_downside_vol(group['LogReturn'], period=252)\n",
    "# )\n",
    "# Reset index if needed\n",
    "df = df.reset_index()\n",
    "\n",
    "\n",
    "# Calculate the mean and standard deviation for AnnualizedStd across the universe on each date\n",
    "df['mu_AnnualizedStd'] = df.groupby('Date')['AnnualizedStd'].transform('mean')\n",
    "df['sigma_AnnualizedStd'] = df.groupby('Date')['AnnualizedStd'].transform('std')\n",
    "\n",
    "# Calculate z-score for volatility\n",
    "df['Z_AnnualizedStd'] = (df['AnnualizedStd'] - df['mu_AnnualizedStd']) / df['sigma_AnnualizedStd']\n",
    "\n",
    "# Invert the z-score for \"Low Vol Score\" (higher score for lower volatility)\n",
    "df['LowVolScore'] = -df['Z_AnnualizedStd']\n",
    "\n",
    "# Normalize the Low Vol Score\n",
    "# Positive z-scores: 1 + score, Negative z-scores: (1 - score) ** -1\n",
    "df['NormalizedLowVolScore'] = np.where(\n",
    "    df['LowVolScore'] >= 0,\n",
    "    1 + df['LowVolScore'],\n",
    "    (1 - df['LowVolScore']) ** -1\n",
    ")\n",
    "df = df.reset_index()\n",
    "df = df.sort_values(by=['Date','Mcap'], ascending=[True,False])\n",
    "df = df[['Date','Symbol','Mcap','Close','NormalizedLowVolScore']]\n",
    "df = df.groupby('Date', group_keys=False).apply(lambda x: x.sort_values(by='Mcap', ascending=False).head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Mcap</th>\n",
       "      <th>Close</th>\n",
       "      <th>NormalizedLowVolScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2993750</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>PGHH</td>\n",
       "      <td>4.769602e+05</td>\n",
       "      <td>14693.45</td>\n",
       "      <td>3.122935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735043</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>NESTLEIND</td>\n",
       "      <td>2.128666e+06</td>\n",
       "      <td>2207.80</td>\n",
       "      <td>3.008872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761223</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>SUNPHARMA</td>\n",
       "      <td>4.316284e+06</td>\n",
       "      <td>1798.95</td>\n",
       "      <td>2.980071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013276</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>DRREDDY</td>\n",
       "      <td>1.081622e+06</td>\n",
       "      <td>1296.25</td>\n",
       "      <td>2.881255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743453</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ICICIBANK</td>\n",
       "      <td>8.481188e+06</td>\n",
       "      <td>1200.45</td>\n",
       "      <td>2.834490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469490</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>GRSE</td>\n",
       "      <td>1.767136e+05</td>\n",
       "      <td>1542.65</td>\n",
       "      <td>0.373175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226138</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>RAYMOND</td>\n",
       "      <td>1.013452e+05</td>\n",
       "      <td>1522.30</td>\n",
       "      <td>0.365934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269879</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>RELINFRA</td>\n",
       "      <td>1.086984e+05</td>\n",
       "      <td>274.40</td>\n",
       "      <td>0.343119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964873</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ITI</td>\n",
       "      <td>3.390490e+05</td>\n",
       "      <td>352.85</td>\n",
       "      <td>0.334300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778279</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>IFCI</td>\n",
       "      <td>1.459952e+05</td>\n",
       "      <td>55.86</td>\n",
       "      <td>0.327425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date     Symbol          Mcap     Close  NormalizedLowVolScore\n",
       "2993750  2025-01-22       PGHH  4.769602e+05  14693.45               3.122935\n",
       "2735043  2025-01-22  NESTLEIND  2.128666e+06   2207.80               3.008872\n",
       "3761223  2025-01-22  SUNPHARMA  4.316284e+06   1798.95               2.980071\n",
       "1013276  2025-01-22    DRREDDY  1.081622e+06   1296.25               2.881255\n",
       "1743453  2025-01-22  ICICIBANK  8.481188e+06   1200.45               2.834490\n",
       "...             ...        ...           ...       ...                    ...\n",
       "1469490  2025-01-22       GRSE  1.767136e+05   1542.65               0.373175\n",
       "3226138  2025-01-22    RAYMOND  1.013452e+05   1522.30               0.365934\n",
       "3269879  2025-01-22   RELINFRA  1.086984e+05    274.40               0.343119\n",
       "1964873  2025-01-22        ITI  3.390490e+05    352.85               0.334300\n",
       "1778279  2025-01-22       IFCI  1.459952e+05     55.86               0.327425\n",
       "\n",
       "[460 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by=['Date','NormalizedLowVolScore'], ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theme_df = d.fetch_data_from_database(table_name='SectorThemeGics')[['Symbol', 'Theme']]\n",
    "# theme = df[['Date', 'Symbol', 'AnnualizedStd','AnnualizedDownVol']].merge(theme_df, on='Symbol', how='inner')\n",
    "\n",
    "# # Group by Date and Theme, and calculate the mean of each momentum score and the count of symbols\n",
    "# df_grouped = theme.groupby(['Date', 'Theme']).agg(\n",
    "#     AnnualizedStdTheme=('AnnualizedStd', 'mean'),\n",
    "#     DownVolTheme=('AnnualizedDownVol', 'mean')).reset_index()\n",
    "# # Define the columns to rank\n",
    "# theme_mom_columns = ['AnnualizedStdTheme','DownVolTheme']\n",
    "\n",
    "# # Calculate the percentile rank for each MoM column, for each date\n",
    "# for col in theme_mom_columns:\n",
    "#     df_grouped[f'{col}_Rank'] = df_grouped.groupby('Date')[col].rank(pct=True, ascending=False)\n",
    "# df_grouped = df_grouped[['Date','Theme','AnnualizedStdTheme_Rank','DownVolTheme_Rank']]\n",
    "\n",
    "# final_mapped_df = theme.merge(df_grouped, on=['Date', 'Theme'], how='left')\n",
    "# final_mapped_df = final_mapped_df.sort_values(by='Date')\n",
    "# final_mapped_df.drop(columns='Theme', inplace=True)\n",
    "# final_mapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Mcap</th>\n",
       "      <th>Close</th>\n",
       "      <th>NormalizedLowVolScore</th>\n",
       "      <th>NormalizedLowVolScore_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3255305</th>\n",
       "      <td>1998-01-05</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>161025.084547</td>\n",
       "      <td>17.360683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884768</th>\n",
       "      <td>1998-01-05</td>\n",
       "      <td>TATASTEEL</td>\n",
       "      <td>52220.172171</td>\n",
       "      <td>7.964170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255306</th>\n",
       "      <td>1998-01-06</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>159717.835383</td>\n",
       "      <td>17.219744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884769</th>\n",
       "      <td>1998-01-06</td>\n",
       "      <td>TATASTEEL</td>\n",
       "      <td>51410.271721</td>\n",
       "      <td>7.840651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255307</th>\n",
       "      <td>1998-01-07</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>161305.209368</td>\n",
       "      <td>17.390884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946302</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ISGEC</td>\n",
       "      <td>86459.674334</td>\n",
       "      <td>1175.850000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174589</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>AMIORG</td>\n",
       "      <td>80720.710369</td>\n",
       "      <td>1971.950000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415785</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>SANSERA</td>\n",
       "      <td>77962.681321</td>\n",
       "      <td>1259.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296480</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>KPIGREEN</td>\n",
       "      <td>76698.735178</td>\n",
       "      <td>389.550000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207404</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>ANURAS</td>\n",
       "      <td>75935.071033</td>\n",
       "      <td>690.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2518985 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date     Symbol           Mcap        Close  \\\n",
       "3255305  1998-01-05   RELIANCE  161025.084547    17.360683   \n",
       "3884768  1998-01-05  TATASTEEL   52220.172171     7.964170   \n",
       "3255306  1998-01-06   RELIANCE  159717.835383    17.219744   \n",
       "3884769  1998-01-06  TATASTEEL   51410.271721     7.840651   \n",
       "3255307  1998-01-07   RELIANCE  161305.209368    17.390884   \n",
       "...             ...        ...            ...          ...   \n",
       "1946302  2025-01-22      ISGEC   86459.674334  1175.850000   \n",
       "174589   2025-01-22     AMIORG   80720.710369  1971.950000   \n",
       "3415785  2025-01-22    SANSERA   77962.681321  1259.050000   \n",
       "2296480  2025-01-22   KPIGREEN   76698.735178   389.550000   \n",
       "207404   2025-01-22     ANURAS   75935.071033   690.750000   \n",
       "\n",
       "         NormalizedLowVolScore  NormalizedLowVolScore_Rank  \n",
       "3255305                    NaN                         NaN  \n",
       "3884768                    NaN                         NaN  \n",
       "3255306                    NaN                         NaN  \n",
       "3884769                    NaN                         NaN  \n",
       "3255307                    NaN                         NaN  \n",
       "...                        ...                         ...  \n",
       "1946302                    NaN                         NaN  \n",
       "174589                     NaN                         NaN  \n",
       "3415785                    NaN                         NaN  \n",
       "2296480                    NaN                         NaN  \n",
       "207404                     NaN                         NaN  \n",
       "\n",
       "[2518985 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the columns to rank\n",
    "vol_columns = ['NormalizedLowVolScore']\n",
    "# Calculate the percentile rank for each MoM column, for each date\n",
    "for col in vol_columns:\n",
    "    df[f'{col}_Rank'] = df.groupby('Date')[col].rank(pct=True, ascending=True)\n",
    "# Define the columns to drop\n",
    "# Drop the specified MoM columns from the DataFrame\n",
    "# df = df.drop(columns=vol_columns)\n",
    "# Define the columns to check for NaN values\n",
    "rank_columns = ['AnnualizedStd_Rank']\n",
    "# rank_columns = ['AnnualizedStdTheme_Rank','DownVolTheme_Rank','AnnualizedStd_Rank','AnnualizedDownVol_Rank']\n",
    "# Drop rows where all specified rank columns are NaN\n",
    "# df = df.dropna(subset=rank_columns, how='all')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = final_mapped_df.filter([\"Symbol\", \"Date\", \"AnnualizedStdTheme_Rank\",\"StdTheme_Rank\",\"AnnualizedStd_Rank\",\"Std_Rank\"])\n",
    "Y = Y.pivot_table(index='Date',columns='Symbol',values='AnnualizedStd_Rank').reset_index()\n",
    "## Convert the long from Dataframe to wide form dataframe\n",
    "## Shifting the Date column\n",
    "Y[\"Date\"] = Y[\"Date\"].shift(-1)\n",
    "## Fill NaN value of date with todays date.\n",
    "Y.iloc[-1, Y.columns.get_loc(\"Date\")] = pd.to_datetime(date.today())\n",
    "## Re-converting the wide form dataframe to long form dataframe\n",
    "Y = Y.melt(id_vars='Date', value_name = \"AnnualizedStd_Rank\")\n",
    "## Drop na and reset the index\n",
    "Y = Y.dropna().reset_index(drop = True)\n",
    "Y = Y[Y[\"Date\"] >= \"2006-01-01\"].reset_index(drop = True).copy()\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the columns to rank\n",
    "# vol_columns = ['AnnualizedStd','AnnualizedDownVol']\n",
    "# # Calculate the percentile rank for each MoM column, for each date\n",
    "# for col in vol_columns:\n",
    "#     final_mapped_df[f'{col}_Rank'] = final_mapped_df.groupby('Date')[col].rank(pct=True, ascending=False)\n",
    "# # Define the columns to drop\n",
    "# # Drop the specified MoM columns from the DataFrame\n",
    "# final_mapped_df = final_mapped_df.drop(columns=vol_columns)\n",
    "# # Define the columns to check for NaN values\n",
    "# rank_columns = ['AnnualizedStdTheme_Rank','DownVolTheme_Rank','AnnualizedStd_Rank','AnnualizedDownVol_Rank']\n",
    "# # Drop rows where all specified rank columns are NaN\n",
    "# final_mapped_df = final_mapped_df.dropna(subset=rank_columns, how='all')\n",
    "# final_mapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_mapped_df = final_mapped_df.sort_values(by=['Date','AnnualizedStd_Rank'], ascending=[True,False])\n",
    "# final_mapped_df['Date'] = final_mapped_df.groupby('Symbol')['Date'].shift(-1)\n",
    "# final_mapped_df = final_mapped_df.dropna(subset=['Date'])\n",
    "# # final_mapped_df['Date'] = final_mapped_df['Date'].fillna(pd.to_datetime('2024-10-24'))\n",
    "# final_mapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_mapped_df['AverageThemeVol_Rank'] = (final_mapped_df['AnnualizedStdTheme_Rank'] + final_mapped_df['DownVolTheme_Rank'])/2\n",
    "# final_mapped_df['AverageVol_Rank'] = (final_mapped_df['AnnualizedStd_Rank'] + final_mapped_df['AnnualizedDownVol_Rank'])/2\n",
    "# final_mapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_mapped_df[final_mapped_df['Date'] == '2024-08-22'].sort_values(by='AnnualizedDownVol_Rank', ascending=False).head(30).to_csv('LastVol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = final_mapped_df[final_mapped_df['Date'] == '2024-10-18'].sort_values(by='AnnualizedDownVol_Rank',ascending=False).head(30)\n",
    "# a.to_csv('Actual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_mapped_df.to_csv('FullVol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = final_mapped_df.filter([\"Symbol\", \"Date\", \"AnnualizedStdTheme_Rank\",\"StdTheme_Rank\",\"AnnualizedStd_Rank\",\"Std_Rank\"])\n",
    "# Y = Y.pivot_table(index='Date',columns='Symbol',values='AnnualizedStd_Rank').reset_index()\n",
    "# ## Convert the long from Dataframe to wide form dataframe\n",
    "# ## Shifting the Date column\n",
    "# Y[\"Date\"] = Y[\"Date\"].shift(-1)\n",
    "# ## Fill NaN value of date with todays date.\n",
    "# Y.iloc[-1, Y.columns.get_loc(\"Date\")] = pd.to_datetime(date.today())\n",
    "# ## Re-converting the wide form dataframe to long form dataframe\n",
    "# Y = Y.melt(id_vars='Date', value_name = \"AnnualizedStd_Rank\")\n",
    "# ## Drop na and reset the index\n",
    "# Y = Y.dropna().reset_index(drop = True)\n",
    "# Y = Y[Y[\"Date\"] >= \"2006-01-01\"].reset_index(drop = True).copy()\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Date'] = df.groupby('Symbol')['Date'].shift(-1)\n",
    "# df = df.dropna(subset=['Date'])\n",
    "# df = df.dropna()\n",
    "# df = df[['Date','Symbol','AnnualizedStd']]\n",
    "# df.to_csv('Volsleeve.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data['Date'] = pd.to_datetime(price_data['Date'], errors='coerce')\n",
    "qualf = df.dropna()\n",
    "qualf = qualf.sort_values(by=['Date','NormalizedLowVolScore'], ascending=[True,False])\n",
    "top_25_stocks_each_day = qualf.groupby('Date').tail(25)\n",
    "top_25_stocks_each_day['Date'] = pd.to_datetime(top_25_stocks_each_day['Date'])\n",
    "rebalanceFrequency=2\n",
    "from rebalancedate import *\n",
    "op=rebalancedates(price_data,'2006-06-02',17, rebalanceFrequency)\n",
    "rebalanceDates=op[1]\n",
    "df_rebalance_dates = pd.DataFrame({'Date': pd.to_datetime(rebalanceDates)})\n",
    "df_rebalance_dates\n",
    "top_25_stocks_each_day = top_25_stocks_each_day[top_25_stocks_each_day['Date'].isin(df_rebalance_dates['Date'])].reset_index(drop=True)\n",
    "top_25_stocks_each_day.to_csv('LowVolShort.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_stocks = 30\n",
    "# df_stocks = df[['Date', 'Symbol', 'AnnualizedStd_Rank']].copy()\n",
    "# df_stocks = df_stocks.groupby('Date').apply(lambda x: x.nsmallest(top_stocks, 'AnnualizedStd_Rank')).reset_index(drop=True)\n",
    "# df_stocks = df_stocks[['Date', 'Symbol', 'AnnualizedStd_Rank']].dropna(subset=['AnnualizedStd_Rank'])\n",
    "# df_stocks['InverseVol'] = 1/df_stocks['AnnualizedStd_Rank']\n",
    "# #Calculate sum of InverseVol for each date\n",
    "# df_stocks['SumInverseVol'] = df_stocks.groupby('Date')['InverseVol'].transform('sum')\n",
    "# # Calculate InverseVol / Sum(InverseVol) for each row\n",
    "# df_stocks['VolWeight'] = df_stocks['InverseVol'] / df_stocks['SumInverseVol']\n",
    "# df_stocks = df_stocks[['Date','Symbol','VolWeight']]\n",
    "# df_stocks['VolWeight'] = df_stocks['VolWeight']*100\n",
    "# df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Mcap</th>\n",
       "      <th>Close</th>\n",
       "      <th>NormalizedLowVolScore</th>\n",
       "      <th>NormalizedLowVolScore_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3923732</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>TECHM</td>\n",
       "      <td>1.648310e+06</td>\n",
       "      <td>1683.95</td>\n",
       "      <td>2.425097</td>\n",
       "      <td>0.882609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date Symbol          Mcap    Close  NormalizedLowVolScore  \\\n",
       "3923732  2025-01-22  TECHM  1.648310e+06  1683.95               2.425097   \n",
       "\n",
       "         NormalizedLowVolScore_Rank  \n",
       "3923732                    0.882609  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[df['Date'] =='2025-01-22'].dropna()\n",
    "x[x['Symbol'] == 'TECHM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stocks[df_stocks['Date'] == '2024-10-17'].sort_values(by='VolWeight', ascending=False).to_csv('InverseWeight30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_vol'] = df.groupby('Date')['AnnualizedStd'].transform('mean')\n",
    "df['STD_vol'] = df.groupby('Date')['AnnualizedStd'].transform('std')\n",
    "# Convert Alpha to Z-score\n",
    "# df['Z_Vol'] = (df['AnnualizedStd'] - df['mean_vol']) / df['STD_vol']\n",
    "# # Calculate Normalized Alpha Quality Score\n",
    "# df['Vol_Score'] = np.where(df['Z_Vol'] >= 0, \n",
    "#                                      1 + df['Z_Vol'], \n",
    "#                                      (1 - df['Z_Vol'])**-1)\n",
    "# df\n",
    "\n",
    "# Calculate reversed Z-score for Volatility\n",
    "df['Z_Vol'] = (df['mean_vol'] - df['AnnualizedStd']) / df['STD_vol']\n",
    "\n",
    "# Calculate Normalized Volatility Quality Score (higher std => lower score)\n",
    "df['Vol_Score'] = np.where(df['Z_Vol'] >= 0, \n",
    "                           1 + df['Z_Vol'], \n",
    "                           (1 - df['Z_Vol'])**-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Mcap</th>\n",
       "      <th>Close</th>\n",
       "      <th>AnnualizedStd</th>\n",
       "      <th>mean_vol</th>\n",
       "      <th>STD_vol</th>\n",
       "      <th>Z_Vol</th>\n",
       "      <th>Vol_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-06-19</td>\n",
       "      <td>MORGANSTAN</td>\n",
       "      <td>2.016612e+04</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>0.252497</td>\n",
       "      <td>0.481456</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>1.845542</td>\n",
       "      <td>2.845542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-06-19</td>\n",
       "      <td>BIOCON</td>\n",
       "      <td>3.438000e+04</td>\n",
       "      <td>28.650000</td>\n",
       "      <td>0.279032</td>\n",
       "      <td>0.481456</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>1.631663</td>\n",
       "      <td>2.631663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-06-19</td>\n",
       "      <td>KANSAINER</td>\n",
       "      <td>1.816401e+04</td>\n",
       "      <td>23.736667</td>\n",
       "      <td>0.279215</td>\n",
       "      <td>0.481456</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>1.630181</td>\n",
       "      <td>2.630181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-06-19</td>\n",
       "      <td>DREDGECORP</td>\n",
       "      <td>1.468600e+04</td>\n",
       "      <td>524.500000</td>\n",
       "      <td>0.281186</td>\n",
       "      <td>0.481456</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>1.614296</td>\n",
       "      <td>2.614296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-06-19</td>\n",
       "      <td>GILLETTE</td>\n",
       "      <td>2.348417e+04</td>\n",
       "      <td>720.700000</td>\n",
       "      <td>0.294859</td>\n",
       "      <td>0.481456</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>1.504080</td>\n",
       "      <td>2.504080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>ITC</td>\n",
       "      <td>6.114965e+06</td>\n",
       "      <td>488.900000</td>\n",
       "      <td>0.190220</td>\n",
       "      <td>0.400311</td>\n",
       "      <td>0.244778</td>\n",
       "      <td>0.858290</td>\n",
       "      <td>1.858290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>DRREDDY</td>\n",
       "      <td>1.118751e+06</td>\n",
       "      <td>1340.810000</td>\n",
       "      <td>0.195868</td>\n",
       "      <td>0.400311</td>\n",
       "      <td>0.244778</td>\n",
       "      <td>0.835218</td>\n",
       "      <td>1.835218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>BATAINDIA</td>\n",
       "      <td>1.844370e+05</td>\n",
       "      <td>1435.000000</td>\n",
       "      <td>0.196166</td>\n",
       "      <td>0.400311</td>\n",
       "      <td>0.244778</td>\n",
       "      <td>0.833999</td>\n",
       "      <td>1.833999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>NESTLEIND</td>\n",
       "      <td>2.293441e+06</td>\n",
       "      <td>2378.700000</td>\n",
       "      <td>0.200413</td>\n",
       "      <td>0.400311</td>\n",
       "      <td>0.244778</td>\n",
       "      <td>0.816650</td>\n",
       "      <td>1.816650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>2024-10-17</td>\n",
       "      <td>ICICIBANK</td>\n",
       "      <td>8.676758e+06</td>\n",
       "      <td>1231.250000</td>\n",
       "      <td>0.202798</td>\n",
       "      <td>0.400311</td>\n",
       "      <td>0.244778</td>\n",
       "      <td>0.806904</td>\n",
       "      <td>1.806904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Symbol          Mcap        Close  AnnualizedStd  \\\n",
       "0    2006-06-19  MORGANSTAN  2.016612e+04    33.600000       0.252497   \n",
       "1    2006-06-19      BIOCON  3.438000e+04    28.650000       0.279032   \n",
       "2    2006-06-19   KANSAINER  1.816401e+04    23.736667       0.279215   \n",
       "3    2006-06-19  DREDGECORP  1.468600e+04   524.500000       0.281186   \n",
       "4    2006-06-19    GILLETTE  2.348417e+04   720.700000       0.294859   \n",
       "...         ...         ...           ...          ...            ...   \n",
       "1105 2024-10-17         ITC  6.114965e+06   488.900000       0.190220   \n",
       "1106 2024-10-17     DRREDDY  1.118751e+06  1340.810000       0.195868   \n",
       "1107 2024-10-17   BATAINDIA  1.844370e+05  1435.000000       0.196166   \n",
       "1108 2024-10-17   NESTLEIND  2.293441e+06  2378.700000       0.200413   \n",
       "1109 2024-10-17   ICICIBANK  8.676758e+06  1231.250000       0.202798   \n",
       "\n",
       "      mean_vol   STD_vol     Z_Vol  Vol_Score  \n",
       "0     0.481456  0.124060  1.845542   2.845542  \n",
       "1     0.481456  0.124060  1.631663   2.631663  \n",
       "2     0.481456  0.124060  1.630181   2.630181  \n",
       "3     0.481456  0.124060  1.614296   2.614296  \n",
       "4     0.481456  0.124060  1.504080   2.504080  \n",
       "...        ...       ...       ...        ...  \n",
       "1105  0.400311  0.244778  0.858290   1.858290  \n",
       "1106  0.400311  0.244778  0.835218   1.835218  \n",
       "1107  0.400311  0.244778  0.833999   1.833999  \n",
       "1108  0.400311  0.244778  0.816650   1.816650  \n",
       "1109  0.400311  0.244778  0.806904   1.806904  \n",
       "\n",
       "[1110 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebalanceFrequency=2\n",
    "from rebalance import *\n",
    "op=rebalanceDates(price_data,'2006-06-02',17, rebalanceFrequency)\n",
    "rebalanceDates=op\n",
    "df_rebalance_dates = pd.DataFrame({'Timestamp': pd.to_datetime(rebalanceDates)})\n",
    "df_rebalance_dates.rename(columns={'Timestamp': 'Date'}, inplace=True)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df = df[df['Date'].isin(df_rebalance_dates['Date'])].reset_index(drop=True)\n",
    "top_stocks = 10\n",
    "df_stocks = df.copy()\n",
    "df_stocks = df_stocks.groupby('Date').apply(lambda x: x.nlargest(top_stocks, 'Vol_Score')).reset_index(drop=True)\n",
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Date','Symbol','NormalizedLowVolScore','NormalizedLowVolScore_Rank']]\n",
    "df.to_csv('Lowvol.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25181818181818183"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnDf = df_stocks.groupby(\"Date\")[\"Symbol\"].apply(set).rename(\"Current\").reset_index()\n",
    "churnDf[\"Previous\"] = churnDf[\"Current\"].shift()\n",
    "churnDf = churnDf.dropna()\n",
    "churnDf[\"Churn\"] = churnDf.apply(lambda x : len(x[\"Current\"] - x[\"Previous\"])/len(x[\"Previous\"]), axis = 1)\n",
    "churnDf[\"Churn\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
